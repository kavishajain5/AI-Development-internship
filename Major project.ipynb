{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data download"
      ],
      "metadata": {
        "id": "egbcn9Z3aZ9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RiCi4Rcipd-J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Download model to check the language from fasttext"
      ],
      "metadata": {
        "id": "Kr_z8VNfaebe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1aUDcugDOSp",
        "outputId": "33c09d90-7a8e-430c-e0a6-ce28f59e7d47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4246763 sha256=40cef475d1c26e0e2a3b036306958290fd48642353233cb82a5b90181bbfc325\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://fasttext.cc/docs/en/language-identification.html\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTS5uXhHOzAA",
        "outputId": "b9a3a7e9-f846-4468-b378-c56302f8d0d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-30 19:38:52--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.78, 13.226.210.15, 13.226.210.25, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 938013 (916K) [binary/octet-stream]\n",
            "Saving to: ‘lid.176.ftz’\n",
            "\n",
            "lid.176.ftz         100%[===================>] 916.03K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-30 19:38:52 (8.87 MB/s) - ‘lid.176.ftz’ saved [938013/938013]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "model = fasttext.load_model('/content/lid.176.ftz')\n",
        "print(model.predict('निचले पटल के लिए डिफोल्ट प्लग-इन खाका', k=1))  # top 2 matching languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394bb762-2123-416c-83a2-89e270f52b28",
        "id": "eoTy0aEUDOSs"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('__label__hi',), array([0.95343572]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "bk17rVccalQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/hindi_english_parallel.csv', nrows=50000)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cyp8a7sXptQr",
        "outputId": "d45ae60f-dded-4803-b742-5b58a77f94a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               hindi  \\\n",
              "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
              "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
              "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
              "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
              "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
              "\n",
              "                                          english  \n",
              "0  Give your application an accessibility workout  \n",
              "1               Accerciser Accessibility Explorer  \n",
              "2  The default plugin layout for the bottom panel  \n",
              "3     The default plugin layout for the top panel  \n",
              "4  A list of plugins that are disabled by default  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6a4ed08-1deb-43fe-844b-11c08782d5f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
              "      <td>Give your application an accessibility workout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
              "      <td>Accerciser Accessibility Explorer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
              "      <td>The default plugin layout for the bottom panel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
              "      <td>The default plugin layout for the top panel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
              "      <td>A list of plugins that are disabled by default</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6a4ed08-1deb-43fe-844b-11c08782d5f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6a4ed08-1deb-43fe-844b-11c08782d5f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6a4ed08-1deb-43fe-844b-11c08782d5f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dcc2e4bf-f29a-467b-8242-c417394eca15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcc2e4bf-f29a-467b-8242-c417394eca15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dcc2e4bf-f29a-467b-8242-c417394eca15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"hindi\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7781,\n        \"samples\": [\n          \"STUN \\u0938\\u0902\\u091c\\u093e\\u0932 \\u091c\\u093e\\u0901\\u091a \\u0938\\u0915\\u094d\\u0930\\u093f\\u092f \\u0915\\u0930\\u0947\\u0902\",\n          \"\\u0905\\u0902\\u091c\\u0941\\u091f\\u093e \\u092c\\u093e\\u0930 \\u092c\\u093e\\u0930 \\u092a\\u0942\\u091b\\u0947 \\u091c\\u093e\\u0928\\u0947 \\u0935\\u093e\\u0932\\u0947 \\u092a\\u094d\\u0930\\u0936\\u094d\\u0928\",\n          \"\\u091c\\u094b\\u0921\\u093c\\u0947\\u0902 \\u0928\\u093f\\u0930\\u0940\\u0915\\u094d\\u0937\\u0923 \\u0915\\u0930\\u0947\\u0902\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8996,\n        \"samples\": [\n          \"Error displaying filter help:% s\",\n          \"Monochrome\",\n          \"MiniDump file with info about the crash\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw-wVw8CrjI-",
        "outputId": "39583046-f75d-4f66-e312-a5f62f8b8846"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "hindi       3\n",
              "english    13\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "bWeF1I3rsCPN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RloOL7IesCMN",
        "outputId": "4551a967-8fd1-4105-de98-49c39d1b3fac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49984, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "UiiL7rP5sCBv",
        "outputId": "fb07d8f8-6e7e-4ad0-d30d-f9a3af142363"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       hindi                     english\n",
              "32930   डेटा परियोजना (_ a)              D _ ata project\n",
              "14784       कृपया लक्ष्य नाम  Please specify target name\n",
              "4333   खेल सांख्यिकी दिखायें    Show gameplay statistics\n",
              "47149                 फंक्शन                    Function"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22c87782-3458-47a7-a182-3c77dcc59978\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32930</th>\n",
              "      <td>डेटा परियोजना (_ a)</td>\n",
              "      <td>D _ ata project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14784</th>\n",
              "      <td>कृपया लक्ष्य नाम</td>\n",
              "      <td>Please specify target name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4333</th>\n",
              "      <td>खेल सांख्यिकी दिखायें</td>\n",
              "      <td>Show gameplay statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47149</th>\n",
              "      <td>फंक्शन</td>\n",
              "      <td>Function</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22c87782-3458-47a7-a182-3c77dcc59978')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22c87782-3458-47a7-a182-3c77dcc59978 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22c87782-3458-47a7-a182-3c77dcc59978');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2192efb2-a359-4c8d-825e-c217b2a61318\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2192efb2-a359-4c8d-825e-c217b2a61318')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2192efb2-a359-4c8d-825e-c217b2a61318 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hindi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u0915\\u0943\\u092a\\u092f\\u093e \\u0932\\u0915\\u094d\\u0937\\u094d\\u092f \\u0928\\u093e\\u092e\",\n          \"\\u092b\\u0902\\u0915\\u094d\\u0936\\u0928\",\n          \"\\u0921\\u0947\\u091f\\u093e \\u092a\\u0930\\u093f\\u092f\\u094b\\u091c\\u0928\\u093e (_ a) \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Please specify target name\",\n          \"Function\",\n          \"D _ ata project\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from string import digits"
      ],
      "metadata": {
        "id": "AyjYCONh8q1k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning dataset"
      ],
      "metadata": {
        "id": "e-5lLTaoaodR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase all characters\n",
        "df['english']=df['english'].apply(lambda x: x.lower())\n",
        "# Remove quotes\n",
        "df['english']=df['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "df['hindi']=df['hindi'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "\n",
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "df['english']=df['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "df['hindi']=df['hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "\n",
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "df['english']=df['english'].apply(lambda x: x.translate(remove_digits))\n",
        "df['hindi']=df['hindi'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "df['hindi'] = df['hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "# if english text in hindi column\n",
        "df['hindi'] = df['hindi'].apply(lambda x: re.sub(\"[A-Za-z]\", \"\", x))\n",
        "\n",
        "# remove extra\n",
        "df['english']=df['english'].apply(lambda x: re.sub('[-_.:;\\[\\]\\|,]', '', x))\n",
        "df['hindi']=df['hindi'].apply(lambda x: re.sub('[-_.;\\[\\]\\|,]', '', x))\n",
        "\n",
        "# Remove extra spaces\n",
        "df['english']=df['english'].apply(lambda x: x.strip())\n",
        "df['hindi']=df['hindi'].apply(lambda x: x.strip())\n",
        "df['english']=df['english'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df['hindi']=df['hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "metadata": {
        "id": "402oxwc29HSN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r7uCzzlS9HO_",
        "outputId": "ae988773-7eed-4124-ce8c-d8988a0ec5ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         hindi                   english\n",
              "24204         सभी फ़ाइल सहेजें            save all files\n",
              "40556            न्यूनतम ऊंचाई                min height\n",
              "682                     यूआरआई                       uri\n",
              "42303             हाशिया दायाँ              margin right\n",
              "21319  बैकअप फ़ाइल नहीं दिखाएँ  do not show backup files"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a8a8ae9-515d-462b-8fe9-2dd2f0cb5735\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24204</th>\n",
              "      <td>सभी फ़ाइल सहेजें</td>\n",
              "      <td>save all files</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40556</th>\n",
              "      <td>न्यूनतम ऊंचाई</td>\n",
              "      <td>min height</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>यूआरआई</td>\n",
              "      <td>uri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42303</th>\n",
              "      <td>हाशिया दायाँ</td>\n",
              "      <td>margin right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21319</th>\n",
              "      <td>बैकअप फ़ाइल नहीं दिखाएँ</td>\n",
              "      <td>do not show backup files</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a8a8ae9-515d-462b-8fe9-2dd2f0cb5735')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a8a8ae9-515d-462b-8fe9-2dd2f0cb5735 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a8a8ae9-515d-462b-8fe9-2dd2f0cb5735');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8248345-335e-40bc-b237-b577e41185ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8248345-335e-40bc-b237-b577e41185ae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8248345-335e-40bc-b237-b577e41185ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"hindi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0928\\u094d\\u092f\\u0942\\u0928\\u0924\\u092e \\u090a\\u0902\\u091a\\u093e\\u0908\",\n          \"\\u092c\\u0948\\u0915\\u0905\\u092a \\u092b\\u093c\\u093e\\u0907\\u0932 \\u0928\\u0939\\u0940\\u0902 \\u0926\\u093f\\u0916\\u093e\\u090f\\u0901\",\n          \"\\u092f\\u0942\\u0906\\u0930\\u0906\\u0908\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"min height\",\n          \"do not show backup files\",\n          \"uri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_hindi'] = True\n",
        "df['is_english'] = True"
      ],
      "metadata": {
        "id": "xM-TyQBQtTyM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check language of text"
      ],
      "metadata": {
        "id": "wn4rTnN3ayN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error = []\n",
        "count = 0\n",
        "for i,row in tqdm(df.iterrows()):\n",
        "\n",
        "  if i == 0:\n",
        "    continue  # Skip the first row to avoid out-of-bounds error\n",
        "\n",
        "    hi_tex = df.iloc[i-1]['hindi']\n",
        "    en_tex = df.iloc[i-1]['english']\n",
        "    try:\n",
        "        hin_pred = model.predict(hi_tex,k=3)[0]\n",
        "        if set(['__label__hi']).issubset(hin_pred) or set(['__label__mr']).issubset(hin_pred):\n",
        "            pass\n",
        "        else:\n",
        "            df.at[i,'is_hindi'] = False\n",
        "            count += 1\n",
        "        en_pred = model.predict(en_tex,k=3)[0]\n",
        "        if set(['__label__en']).issubset(en_pred):\n",
        "            pass\n",
        "        else:\n",
        "            df.at[i,'is_english'] = False\n",
        "            count += 1\n",
        "    except:\n",
        "        error.append(i)"
      ],
      "metadata": {
        "id": "v6DcemYks9cU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43f8f42-2880-4c22-ec45-f9a4833305d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "49984it [00:03, 16440.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.is_english == False].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx7uOKqxAi_5",
        "outputId": "bf5b816b-279b-4540-ac19-b9b58dd3d6d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.is_hindi == False].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erx9UF_UAn1S",
        "outputId": "ced0ff6c-642e-4cd2-a532-bbe9eb49dcaf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmVSPp9v_oeo",
        "outputId": "6210d787-104a-4fb2-cdb2-a58811ab6f58"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49984, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~df.is_hindi == False]\n",
        "df = df[~df.is_english == False]\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44fSLirjy769",
        "outputId": "40a2f337-ae07-42bb-f65a-5537018a4e85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49984, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['is_hindi','is_english'],inplace=True)"
      ],
      "metadata": {
        "id": "vZUzaM04De75"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Len of sentence"
      ],
      "metadata": {
        "id": "1PuVr2emE0Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['hindi_len'] = df['hindi'].apply(lambda x: len(x.split()))\n",
        "df['english_len'] = df['english'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "J7kf5J3lEkHv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df.hindi_len, bins=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Wt58A0bqEkFM",
        "outputId": "544fb031-3745-4566-bf1d-cf2a239a0344"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='hindi_len', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGxCAYAAAB/QoKnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwD0lEQVR4nO3de3RU5b3/8U/uCZdJuEgCkkjwAgQhSAJhtDc0Em10ieA54EGaAuqRJghJEaEiINbG4hFBQeLlSOyvcricpVZAwRgk1BJuE1MBIZUeNBxhEhSTAYQEkv37oye7jEF9iAMzgfdrrb0Wez/fPPOdp5f5rL337AmyLMsSAAAAvlOwvxsAAABoDQhNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABkL93cDForGxUQcPHlT79u0VFBTk73YAAIABy7J09OhRdevWTcHB330uidDkIwcPHlR8fLy/2wAAAC1w4MABde/e/TtrCE0+0r59e0n/WHSHw+HnbgAAgAmPx6P4+Hj7c/y7EJp8pOmSnMPhIDQBANDKmNxaw43gAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABvwamubMmaOgoCCvrXfv3vb4yZMnlZ2drU6dOqldu3YaOXKkqqqqvOaorKxUZmam2rRpoy5duuihhx7S6dOnvWo2btyogQMHKiIiQldddZUKCwub9bJ48WL16NFDkZGRSktL07Zt287LewYAAK2T38809e3bV4cOHbK3Dz74wB7Lzc3V6tWrtWrVKpWUlOjgwYMaMWKEPd7Q0KDMzEzV19dr8+bNevXVV1VYWKhZs2bZNfv371dmZqaGDh2q8vJyTZkyRffee6/Wr19v16xYsUJ5eXmaPXu2ysrKlJycrIyMDFVXV1+YRQAAAIHP8qPZs2dbycnJZx2rqamxwsLCrFWrVtnH9uzZY0mySktLLcuyrLffftsKDg623G63XbNkyRLL4XBYdXV1lmVZ1rRp06y+fft6zT1q1CgrIyPD3h88eLCVnZ1t7zc0NFjdunWz8vPzjd9LbW2tJcmqra01/hsAAOBf5/L57fczTZ988om6deumnj17asyYMaqsrJQkuVwunTp1Sunp6XZt7969lZCQoNLSUklSaWmp+vXrp9jYWLsmIyNDHo9Hu3fvtmvOnKOppmmO+vp6uVwur5rg4GClp6fbNQAAAH79GZW0tDQVFhaqV69eOnTokB577DH9+Mc/1q5du+R2uxUeHq6YmBivv4mNjZXb7ZYkud1ur8DUNN409l01Ho9HJ06c0FdffaWGhoaz1uzdu/dbe6+rq1NdXZ297/F4zu3NAwCAVsWvoenWW2+1/92/f3+lpaXpiiuu0MqVKxUVFeXHzr5ffn6+HnvsMX+3AQAALhC/X547U0xMjK655hrt27dPcXFxqq+vV01NjVdNVVWV4uLiJElxcXHNvk3XtP99NQ6HQ1FRUercubNCQkLOWtM0x9nMmDFDtbW19nbgwIEWvWcAANA6BFRoOnbsmP7+97+ra9euSklJUVhYmIqLi+3xiooKVVZWyul0SpKcTqd27tzp9S23oqIiORwOJSUl2TVnztFU0zRHeHi4UlJSvGoaGxtVXFxs15xNRESEHA6H1wYAAC5efr08N3XqVN1+++264oordPDgQc2ePVshISG6++67FR0drQkTJigvL08dO3aUw+HQpEmT5HQ6NWTIEEnSsGHDlJSUpLFjx2revHlyu92aOXOmsrOzFRERIUl64IEHtGjRIk2bNk3jx4/Xhg0btHLlSq1du9buIy8vT1lZWUpNTdXgwYO1YMECHT9+XOPGjfPLupxNZWWlvvjiC3+3cdHr3LmzEhIS/N0GACAQXYBv832rUaNGWV27drXCw8Otyy+/3Bo1apS1b98+e/zEiRPWr371K6tDhw5WmzZtrDvvvNM6dOiQ1xyffvqpdeutt1pRUVFW586drV//+tfWqVOnvGref/99a8CAAVZ4eLjVs2dPa+nSpc16ee6556yEhAQrPDzcGjx4sLVly5Zzei/n85EDn332mRUV1caSxHaet6ioNtZnn33m8/8MAQCB6Vw+v4Msy7IM8xW+g8fjUXR0tGpra31+qa6srEwpKSlKGz9bjq49fDo3/slz6FNtfeUxuVwuDRw40N/tAAAugHP5/Pbr5TmcG0fXHuqY0MvfbQAAcEkKqBvBAQAAAhWhCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwEDAhKYnn3xSQUFBmjJlin3s5MmTys7OVqdOndSuXTuNHDlSVVVVXn9XWVmpzMxMtWnTRl26dNFDDz2k06dPe9Vs3LhRAwcOVEREhK666ioVFhY2e/3FixerR48eioyMVFpamrZt23Y+3iYAAGilAiI0bd++XS+88IL69+/vdTw3N1erV6/WqlWrVFJSooMHD2rEiBH2eENDgzIzM1VfX6/Nmzfr1VdfVWFhoWbNmmXX7N+/X5mZmRo6dKjKy8s1ZcoU3XvvvVq/fr1ds2LFCuXl5Wn27NkqKytTcnKyMjIyVF1dff7fPAAAaBX8HpqOHTumMWPG6KWXXlKHDh3s47W1tfrP//xPzZ8/XzfeeKNSUlK0dOlSbd68WVu2bJEkvfvuu/r444/1xz/+UQMGDNCtt96qxx9/XIsXL1Z9fb0kqaCgQImJiXr66afVp08f5eTk6K677tIzzzxjv9b8+fN13333ady4cUpKSlJBQYHatGmjV1555cIuBgAACFh+D03Z2dnKzMxUenq613GXy6VTp055He/du7cSEhJUWloqSSotLVW/fv0UGxtr12RkZMjj8Wj37t12zTfnzsjIsOeor6+Xy+XyqgkODlZ6erpdAwAAEOrPF1++fLnKysq0ffv2ZmNut1vh4eGKiYnxOh4bGyu3223XnBmYmsabxr6rxuPx6MSJE/rqq6/U0NBw1pq9e/d+a+91dXWqq6uz9z0ez/e8WwAA0Jr57UzTgQMHNHnyZL322muKjIz0Vxstlp+fr+joaHuLj4/3d0sAAOA88ltocrlcqq6u1sCBAxUaGqrQ0FCVlJTo2WefVWhoqGJjY1VfX6+amhqvv6uqqlJcXJwkKS4urtm36Zr2v6/G4XAoKipKnTt3VkhIyFlrmuY4mxkzZqi2ttbeDhw40KJ1AAAArYPfQtNNN92knTt3qry83N5SU1M1ZswY+99hYWEqLi62/6aiokKVlZVyOp2SJKfTqZ07d3p9y62oqEgOh0NJSUl2zZlzNNU0zREeHq6UlBSvmsbGRhUXF9s1ZxMRESGHw+G1AQCAi5ff7mlq3769rr32Wq9jbdu2VadOnezjEyZMUF5enjp27CiHw6FJkybJ6XRqyJAhkqRhw4YpKSlJY8eO1bx58+R2uzVz5kxlZ2crIiJCkvTAAw9o0aJFmjZtmsaPH68NGzZo5cqVWrt2rf26eXl5ysrKUmpqqgYPHqwFCxbo+PHjGjdu3AVaDQAAEOj8eiP493nmmWcUHByskSNHqq6uThkZGXr++eft8ZCQEK1Zs0YTJ06U0+lU27ZtlZWVpblz59o1iYmJWrt2rXJzc7Vw4UJ1795dL7/8sjIyMuyaUaNG6fDhw5o1a5bcbrcGDBigdevWNbs5HAAAXLqCLMuy/N3ExcDj8Sg6Olq1tbU+v1RXVlamlJQU3fzIUnVM6OXTufFPRyorVPTEOLlcLg0cONDf7QAALoBz+fz2+3OaAAAAWgNCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAFCEwAAgAG/hqYlS5aof//+cjgccjgccjqdeuedd+zxkydPKjs7W506dVK7du00cuRIVVVVec1RWVmpzMxMtWnTRl26dNFDDz2k06dPe9Vs3LhRAwcOVEREhK666ioVFhY262Xx4sXq0aOHIiMjlZaWpm3btp2X9wwAAFonv4am7t2768knn5TL5dKOHTt044036o477tDu3bslSbm5uVq9erVWrVqlkpISHTx4UCNGjLD/vqGhQZmZmaqvr9fmzZv16quvqrCwULNmzbJr9u/fr8zMTA0dOlTl5eWaMmWK7r33Xq1fv96uWbFihfLy8jR79myVlZUpOTlZGRkZqq6uvnCLAQAAAlqQZVmWv5s4U8eOHfXUU0/prrvu0mWXXaZly5bprrvukiTt3btXffr0UWlpqYYMGaJ33nlHt912mw4ePKjY2FhJUkFBgR5++GEdPnxY4eHhevjhh7V27Vrt2rXLfo3Ro0erpqZG69atkySlpaVp0KBBWrRokSSpsbFR8fHxmjRpkqZPn27Ut8fjUXR0tGpra+VwOHy5JCorK1NKSopufmSpOib08unc+KcjlRUqemKcXC6XBg4c6O92AAAXwLl8fgfMPU0NDQ1avny5jh8/LqfTKZfLpVOnTik9Pd2u6d27txISElRaWipJKi0tVb9+/ezAJEkZGRnyeDz22arS0lKvOZpqmuaor6+Xy+XyqgkODlZ6erpdAwAAEOrvBnbu3Cmn06mTJ0+qXbt2euONN5SUlKTy8nKFh4crJibGqz42NlZut1uS5Ha7vQJT03jT2HfVeDwenThxQl999ZUaGhrOWrN3795v7buurk51dXX2vsfjObc3DgAAWhW/n2nq1auXysvLtXXrVk2cOFFZWVn6+OOP/d3W98rPz1d0dLS9xcfH+7slAABwHvk9NIWHh+uqq65SSkqK8vPzlZycrIULFyouLk719fWqqanxqq+qqlJcXJwkKS4urtm36Zr2v6/G4XAoKipKnTt3VkhIyFlrmuY4mxkzZqi2ttbeDhw40KL3DwAAWge/h6ZvamxsVF1dnVJSUhQWFqbi4mJ7rKKiQpWVlXI6nZIkp9OpnTt3en3LraioSA6HQ0lJSXbNmXM01TTNER4erpSUFK+axsZGFRcX2zVnExERYT8qoWkDAAAXL7/e0zRjxgzdeuutSkhI0NGjR7Vs2TJt3LhR69evV3R0tCZMmKC8vDx17NhRDodDkyZNktPp1JAhQyRJw4YNU1JSksaOHat58+bJ7XZr5syZys7OVkREhCTpgQce0KJFizRt2jSNHz9eGzZs0MqVK7V27Vq7j7y8PGVlZSk1NVWDBw/WggULdPz4cY0bN84v6wIAAAKPX0NTdXW1fvGLX+jQoUOKjo5W//79tX79et18882SpGeeeUbBwcEaOXKk6urqlJGRoeeff97++5CQEK1Zs0YTJ06U0+lU27ZtlZWVpblz59o1iYmJWrt2rXJzc7Vw4UJ1795dL7/8sjIyMuyaUaNG6fDhw5o1a5bcbrcGDBigdevWNbs5HAAAXLoC7jlNrRXPaWr9eE4TAFx6WuVzmgAAAAIZoQkAAMAAoQkAAMAAoQkAAMBAi0JTz5499eWXXzY7XlNTo549e/7gpgAAAAJNi0LTp59+qoaGhmbH6+rq9Pnnn//gpgAAAALNOT2n6a233rL/3fQAyiYNDQ0qLi5Wjx49fNYcAABAoDin0DR8+HBJUlBQkLKysrzGwsLC1KNHDz399NM+aw4AACBQnFNoamxslPSPp2xv375dnTt3Pi9NAQAABJoW/YzK/v37fd0HAABAQGvxb88VFxeruLhY1dXV9hmoJq+88soPbgwAACCQtCg0PfbYY5o7d65SU1PVtWtXBQUF+bovAACAgNKi0FRQUKDCwkKNHTvW1/0AAAAEpBY9p6m+vl7XX3+9r3sBAAAIWC0KTffee6+WLVvm614AAAACVosuz508eVIvvvii3nvvPfXv319hYWFe4/Pnz/dJcwAAAIGiRaHpo48+0oABAyRJu3bt8hrjpnAAAHAxalFoev/9933dBwAAQEBr0T1NAAAAl5oWnWkaOnTod16G27BhQ4sbAgAACEQtCk1N9zM1OXXqlMrLy7Vr165mP+QLAABwMWhRaHrmmWfOenzOnDk6duzYD2oIAAAgEPn0nqZ77rmH350DAAAXJZ+GptLSUkVGRvpySgAAgIDQostzI0aM8Nq3LEuHDh3Sjh079Oijj/qkMQAAgEDSotAUHR3ttR8cHKxevXpp7ty5GjZsmE8aAwAACCQtCk1Lly71dR8AAAABrUWhqYnL5dKePXskSX379tV1113nk6YAAAACTYtCU3V1tUaPHq2NGzcqJiZGklRTU6OhQ4dq+fLluuyyy3zZIwAAgN+16NtzkyZN0tGjR7V7924dOXJER44c0a5du+TxePTggw/6ukcAAAC/a9GZpnXr1um9995Tnz597GNJSUlavHgxN4IDAICLUovONDU2NiosLKzZ8bCwMDU2Nv7gpgAAAAJNi0LTjTfeqMmTJ+vgwYP2sc8//1y5ubm66aabfNYcAABAoGhRaFq0aJE8Ho969OihK6+8UldeeaUSExPl8Xj03HPP+bpHAAAAv2vRPU3x8fEqKyvTe++9p71790qS+vTpo/T0dJ82BwAAECjO6UzThg0blJSUJI/Ho6CgIN18882aNGmSJk2apEGDBqlv377685//fL56BQAA8JtzCk0LFizQfffdJ4fD0WwsOjpa//7v/6758+f7rDkAAIBAcU6h6a9//atuueWWbx0fNmyYXC7XD24KAAAg0JxTaKqqqjrrowaahIaG6vDhwz+4KQAAgEBzTqHp8ssv165du751/KOPPlLXrl1/cFMAAACB5pxC089//nM9+uijOnnyZLOxEydOaPbs2brtttt81hwAAECgOKdHDsycOVOvv/66rrnmGuXk5KhXr16SpL1792rx4sVqaGjQI488cl4aBQAA8KdzCk2xsbHavHmzJk6cqBkzZsiyLElSUFCQMjIytHjxYsXGxp6XRgEAAPzpnB9uecUVV+jtt9/WV199pX379smyLF199dXq0KHD+egPAAAgILToieCS1KFDBw0aNMiXvQAAAASsFv32HAAAwKWG0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGDAr6EpPz9fgwYNUvv27dWlSxcNHz5cFRUVXjUnT55Udna2OnXqpHbt2mnkyJGqqqryqqmsrFRmZqbatGmjLl266KGHHtLp06e9ajZu3KiBAwcqIiJCV111lQoLC5v1s3jxYvXo0UORkZFKS0vTtm3bfP6eAQBA6+TX0FRSUqLs7Gxt2bJFRUVFOnXqlIYNG6bjx4/bNbm5uVq9erVWrVqlkpISHTx4UCNGjLDHGxoalJmZqfr6em3evFmvvvqqCgsLNWvWLLtm//79yszM1NChQ1VeXq4pU6bo3nvv1fr16+2aFStWKC8vT7Nnz1ZZWZmSk5OVkZGh6urqC7MYAAAgoAVZlmX5u4kmhw8fVpcuXVRSUqKf/OQnqq2t1WWXXaZly5bprrvukiTt3btXffr0UWlpqYYMGaJ33nlHt912mw4ePKjY2FhJUkFBgR5++GEdPnxY4eHhevjhh7V27Vrt2rXLfq3Ro0erpqZG69atkySlpaVp0KBBWrRokSSpsbFR8fHxmjRpkqZPn/69vXs8HkVHR6u2tlYOh8On61JWVqaUlBTd/MhSdUzo5dO58U9HKitU9MQ4uVwuDRw40N/tAAAugHP5/A6oe5pqa2slSR07dpQkuVwunTp1Sunp6XZN7969lZCQoNLSUklSaWmp+vXrZwcmScrIyJDH49Hu3bvtmjPnaKppmqO+vl4ul8urJjg4WOnp6XbNN9XV1cnj8XhtAADg4hUwoamxsVFTpkzRDTfcoGuvvVaS5Ha7FR4erpiYGK/a2NhYud1uu+bMwNQ03jT2XTUej0cnTpzQF198oYaGhrPWNM3xTfn5+YqOjra3+Pj4lr1xAADQKgRMaMrOztauXbu0fPlyf7diZMaMGaqtrbW3AwcO+LslAABwHoX6uwFJysnJ0Zo1a7Rp0yZ1797dPh4XF6f6+nrV1NR4nW2qqqpSXFycXfPNb7k1fbvuzJpvfuOuqqpKDodDUVFRCgkJUUhIyFlrmub4poiICEVERLTsDQMAgFbHr2eaLMtSTk6O3njjDW3YsEGJiYle4ykpKQoLC1NxcbF9rKKiQpWVlXI6nZIkp9OpnTt3en3LraioSA6HQ0lJSXbNmXM01TTNER4erpSUFK+axsZGFRcX2zUAAODS5tczTdnZ2Vq2bJn+9Kc/qX379vb9Q9HR0YqKilJ0dLQmTJigvLw8dezYUQ6HQ5MmTZLT6dSQIUMkScOGDVNSUpLGjh2refPmye12a+bMmcrOzrbPBD3wwANatGiRpk2bpvHjx2vDhg1auXKl1q5da/eSl5enrKwspaamavDgwVqwYIGOHz+ucePGXfiFAQAAAcevoWnJkiWSpJ/97Gdex5cuXapf/vKXkqRnnnlGwcHBGjlypOrq6pSRkaHnn3/erg0JCdGaNWs0ceJEOZ1OtW3bVllZWZo7d65dk5iYqLVr1yo3N1cLFy5U9+7d9fLLLysjI8OuGTVqlA4fPqxZs2bJ7XZrwIABWrduXbObwwEAwKUpoJ7T1JrxnKbWj+c0AcClp9U+pwkAACBQEZoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAM+DU0bdq0Sbfffru6deumoKAgvfnmm17jlmVp1qxZ6tq1q6KiopSenq5PPvnEq+bIkSMaM2aMHA6HYmJiNGHCBB07dsyr5qOPPtKPf/xjRUZGKj4+XvPmzWvWy6pVq9S7d29FRkaqX79+evvtt33+fgEAQOvl19B0/PhxJScna/HixWcdnzdvnp599lkVFBRo69atatu2rTIyMnTy5Em7ZsyYMdq9e7eKioq0Zs0abdq0Sffff7897vF4NGzYMF1xxRVyuVx66qmnNGfOHL344ot2zebNm3X33XdrwoQJ+vDDDzV8+HANHz5cu3btOn9vHgAAtCpBlmVZ/m5CkoKCgvTGG29o+PDhkv5xlqlbt2769a9/ralTp0qSamtrFRsbq8LCQo0ePVp79uxRUlKStm/frtTUVEnSunXr9POf/1z/+7//q27dumnJkiV65JFH5Ha7FR4eLkmaPn263nzzTe3du1eSNGrUKB0/flxr1qyx+xkyZIgGDBiggoICo/49Ho+io6NVW1srh8Phq2WRJJWVlSklJUU3P7JUHRN6+XRu/NORygoVPTFOLpdLAwcO9Hc7AIAL4Fw+vwP2nqb9+/fL7XYrPT3dPhYdHa20tDSVlpZKkkpLSxUTE2MHJklKT09XcHCwtm7datf85Cc/sQOTJGVkZKiiokJfffWVXXPm6zTVNL3O2dTV1cnj8XhtAADg4hWwocntdkuSYmNjvY7HxsbaY263W126dPEaDw0NVceOHb1qzjbHma/xbTVN42eTn5+v6Ohoe4uPjz/XtwgAAFqRgA1NgW7GjBmqra21twMHDvi7JQAAcB4FbGiKi4uTJFVVVXkdr6qqssfi4uJUXV3tNX769GkdOXLEq+Zsc5z5Gt9W0zR+NhEREXI4HF4bAAC4eAVsaEpMTFRcXJyKi4vtYx6PR1u3bpXT6ZQkOZ1O1dTUyOVy2TUbNmxQY2Oj0tLS7JpNmzbp1KlTdk1RUZF69eqlDh062DVnvk5TTdPrAAAA+DU0HTt2TOXl5SovL5f0j5u/y8vLVVlZqaCgIE2ZMkW//e1v9dZbb2nnzp36xS9+oW7dutnfsOvTp49uueUW3Xfffdq2bZv+8pe/KCcnR6NHj1a3bt0kSf/2b/+m8PBwTZgwQbt379aKFSu0cOFC5eXl2X1MnjxZ69at09NPP629e/dqzpw52rFjh3Jyci70kgAAgAAV6s8X37Fjh4YOHWrvNwWZrKwsFRYWatq0aTp+/Ljuv/9+1dTU6Ec/+pHWrVunyMhI+29ee+015eTk6KabblJwcLBGjhypZ5991h6Pjo7Wu+++q+zsbKWkpKhz586aNWuW17Ocrr/+ei1btkwzZ87Ub37zG1199dV68803de21116AVQAAAK1BwDynqbXjOU2tH89pAoBLz0XxnCYAAIBAQmgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwEOrvBgLN4sWL9dRTT8ntdis5OVnPPfecBg8e7O+2cAHt2bPH3y1c9Dp37qyEhAR/twEA54TQdIYVK1YoLy9PBQUFSktL04IFC5SRkaGKigp16dLF3+3hPDtR+6WkIN1zzz3+buWiFxXVRnv37iE4AWhVCE1nmD9/vu677z6NGzdOklRQUKC1a9fqlVde0fTp0/3cHc63U18flWRpwL89rMsSe/u7nYuW59Cn2vrKY/riiy8ITQBaFULT/6mvr5fL5dKMGTPsY8HBwUpPT1dpaakfO8OF1q5Lgjom9PJ3Gxc9LoOef3V1dYqIiPB3Gxc9LjdfOghN/+eLL75QQ0ODYmNjvY7HxsZq7969zerr6upUV1dn79fW1kqSPB6Pz3s7duyYJOnIZxU6XXfC5/PjHzyHPpMk1X7+icJCg/zczcXri7/vlCQug+KiERERqf/3//7Q7PMDvhcXF6e4uDifztn0uW1Z1vfWEppaKD8/X4899liz4/Hx8eftNV1/fPK8zY1/2rlqgb9bANCK1NWd1L/+67/6uw38QEePHlV0dPR31hCa/k/nzp0VEhKiqqoqr+NVVVVnTbUzZsxQXl6evd/Y2KgjR46oU6dOCgry7VkKj8ej+Ph4HThwQA6Hw6dzX0pYR99gHX2DdfQN1tE3LuV1tCxLR48eVbdu3b63ltD0f8LDw5WSkqLi4mINHz5c0j+CUHFxsXJycprVR0RENLtXICYm5rz26HA4Lrn/Mp8PrKNvsI6+wTr6BuvoG5fqOn7fGaYmhKYz5OXlKSsrS6mpqRo8eLAWLFig48eP29+mAwAAly5C0xlGjRqlw4cPa9asWXK73RowYIDWrVvHzX0AAIDQ9E05OTlnvRznTxEREZo9ezZfHf6BWEffYB19g3X0DdbRN1hHM0GWyXfsAAAALnH8YC8AAIABQhMAAIABQhMAAIABQlOAW7x4sXr06KHIyEilpaVp27Zt/m4poOXn52vQoEFq3769unTpouHDh6uiosKr5uTJk8rOzlanTp3Url07jRw5stlDTeHtySefVFBQkKZMmWIfYx3NfP7557rnnnvUqVMnRUVFqV+/ftqxY4c9blmWZs2apa5duyoqKkrp6en65JNP/Nhx4GloaNCjjz6qxMRERUVF6corr9Tjjz/u9bMXrGNzmzZt0u23365u3bopKChIb775pte4yZodOXJEY8aMkcPhUExMjCZMmGD/tNeliNAUwFasWKG8vDzNnj1bZWVlSk5OVkZGhqqrq/3dWsAqKSlRdna2tmzZoqKiIp06dUrDhg3T8ePH7Zrc3FytXr1aq1atUklJiQ4ePKgRI0b4sevAtn37dr3wwgvq37+/13HW8ft99dVXuuGGGxQWFqZ33nlHH3/8sZ5++ml16NDBrpk3b56effZZFRQUaOvWrWrbtq0yMjJ08uRJP3YeWH7/+99ryZIlWrRokfbs2aPf//73mjdvnp577jm7hnVs7vjx40pOTtbixYvPOm6yZmPGjNHu3btVVFSkNWvWaNOmTbr//vsv1FsIPBYC1uDBg63s7Gx7v6GhwerWrZuVn5/vx65al+rqakuSVVJSYlmWZdXU1FhhYWHWqlWr7Jo9e/ZYkqzS0lJ/tRmwjh49al199dVWUVGR9dOf/tSaPHmyZVmso6mHH37Y+tGPfvSt442NjVZcXJz11FNP2cdqamqsiIgI67/+678uRIutQmZmpjV+/HivYyNGjLDGjBljWRbraEKS9cYbb9j7Jmv28ccfW5Ks7du32zXvvPOOFRQUZH3++ecXrPdAwpmmAFVfXy+Xy6X09HT7WHBwsNLT01VaWurHzlqX2tpaSVLHjh0lSS6XS6dOnfJa1969eyshIYF1PYvs7GxlZmZ6rZfEOpp66623lJqaqn/5l39Rly5ddN111+mll16yx/fv3y+32+21jtHR0UpLS2Mdz3D99deruLhYf/vb3yRJf/3rX/XBBx/o1ltvlcQ6toTJmpWWliomJkapqal2TXp6uoKDg7V169YL3nMg4OGWAeqLL75QQ0NDs6eRx8bGau/evX7qqnVpbGzUlClTdMMNN+jaa6+VJLndboWHhzf7ncDY2Fi53W4/dBm4li9frrKyMm3fvr3ZGOto5n/+53+0ZMkS5eXl6Te/+Y22b9+uBx98UOHh4crKyrLX6mz/O2cd/2n69OnyeDzq3bu3QkJC1NDQoCeeeEJjxoyRJNaxBUzWzO12q0uXLl7joaGh6tix4yW7roQmXLSys7O1a9cuffDBB/5updU5cOCAJk+erKKiIkVGRvq7nVarsbFRqamp+t3vfidJuu6667Rr1y4VFBQoKyvLz921HitXrtRrr72mZcuWqW/fviovL9eUKVPUrVs31hEXFJfnAlTnzp0VEhLS7NtIVVVViouL81NXrUdOTo7WrFmj999/X927d7ePx8XFqb6+XjU1NV71rKs3l8ul6upqDRw4UKGhoQoNDVVJSYmeffZZhYaGKjY2lnU00LVrVyUlJXkd69OnjyorKyXJXiv+d/7dHnroIU2fPl2jR49Wv379NHbsWOXm5io/P18S69gSJmsWFxfX7ItHp0+f1pEjRy7ZdSU0Bajw8HClpKSouLjYPtbY2Kji4mI5nU4/dhbYLMtSTk6O3njjDW3YsEGJiYle4ykpKQoLC/Na14qKClVWVrKuZ7jpppu0c+dOlZeX21tqaqrGjBlj/5t1/H433HBDs0de/O1vf9MVV1whSUpMTFRcXJzXOno8Hm3dupV1PMPXX3+t4GDvj6uQkBA1NjZKYh1bwmTNnE6nampq5HK57JoNGzaosbFRaWlpF7zngODvO9Hx7ZYvX25FRERYhYWF1scff2zdf//9VkxMjOV2u/3dWsCaOHGiFR0dbW3cuNE6dOiQvX399dd2zQMPPGAlJCRYGzZssHbs2GE5nU7L6XT6sevW4cxvz1kW62hi27ZtVmhoqPXEE09Yn3zyifXaa69Zbdq0sf74xz/aNU8++aQVExNj/elPf7I++ugj64477rASExOtEydO+LHzwJKVlWVdfvnl1po1a6z9+/dbr7/+utW5c2dr2rRpdg3r2NzRo0etDz/80Prwww8tSdb8+fOtDz/80Prss88syzJbs1tuucW67rrrrK1bt1offPCBdfXVV1t33323v96S3xGaAtxzzz1nJSQkWOHh4dbgwYOtLVu2+LulgCbprNvSpUvtmhMnTli/+tWvrA4dOlht2rSx7rzzTuvQoUP+a7qV+GZoYh3NrF692rr22mutiIgIq3fv3taLL77oNd7Y2Gg9+uijVmxsrBUREWHddNNNVkVFhZ+6DUwej8eaPHmylZCQYEVGRlo9e/a0HnnkEauurs6uYR2be//998/6/4dZWVmWZZmt2ZdffmndfffdVrt27SyHw2GNGzfOOnr0qB/eTWAIsqwzHqkKAACAs+KeJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgCtys9+9jNNmTLlW8eDgoL05ptv/qDXKCwsVExMjL0/Z84cDRgwwOhvf/nLX2r48OE/6PUBBKZQfzcAAL506NAhdejQwadzTp06VZMmTfLpnABaH0ITgItKXFycz+ds166d2rVr5/N5AbQuXJ4D0Oo0NjZq2rRp6tixo+Li4jRnzhx77MzLc59++qmCgoL0+uuva+jQoWrTpo2Sk5NVWlrqNV9hYaESEhLUpk0b3Xnnnfryyy+9xs/l8tzZes3Pz1diYqKioqKUnJys//7v/7bHN27cqKCgIBUXFys1NVVt2rTR9ddfr4qKiha9HoDzh9AEoNV59dVX1bZtW23dulXz5s3T3LlzVVRU9K31jzzyiKZOnary8nJdc801uvvuu3X69GlJ0tatWzVhwgTl5OSovLxcQ4cO1W9/+1uf9Zqfn68//OEPKigo0O7du5Wbm6t77rlHJSUlzXp8+umntWPHDoWGhmr8+PE+6wGAb3B5DkCr079/f82ePVuSdPXVV2vRokUqLi7WzTfffNb6qVOnKjMzU5L02GOPqW/fvtq3b5969+6thQsX6pZbbtG0adMkSddcc402b96sdevW/eA+6+rq9Lvf/U7vvfeenE6nJKlnz5764IMP9MILL+inP/2pXfvEE0/Y+9OnT1dmZqZOnjypyMjIH9wHAN/gTBOAVqd///5e+127dlV1dbVRfdeuXSXJrt+zZ4/S0tK86psCzg+1b98+ff3117r55pvt+6LatWunP/zhD/r73/9u3COAwMCZJgCtTlhYmNd+UFCQGhsbjeqDgoIk6TvrfeXYsWOSpLVr1+ryyy/3GouIiPDa91ePAMwRmgBc0vr06aOtW7d6HduyZYtP5k5KSlJERIQqKyu9LsUBaJ0ITQAuaQ8++KBuuOEG/cd//IfuuOMOrV+/3if3M0lS+/btNXXqVOXm5qqxsVE/+tGPVFtbq7/85S9yOBzKysryyesAuDC4pwnAJW3IkCF66aWXtHDhQiUnJ+vdd9/VzJkzfTb/448/rkcffVT5+fnq06ePbrnlFq1du1aJiYk+ew0AF0aQZVmWv5sAAAAIdJxpAgAAMEBoAoBzcOajA765/fnPf/Z3ewDOIy7PAcA52Ldv37eOXX755YqKirqA3QC4kAhNAAAABrg8BwAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYOD/A3D5+ZlqPZcpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df.english_len, bins=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "zO_XhcMCEkCP",
        "outputId": "c12f4bab-49d3-4b29-9a51-902a80604f2c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='english_len', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english\n",
        "for i in np.arange(0.1,1.1,0.1):\n",
        "    print('{0} Quantile is {1}'.format(int(i*100),np.quantile(df.english_len, i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD9rfn45FGsw",
        "outputId": "019509d7-5416-4926-9593-0799c97b76b4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Quantile is 1.0\n",
            "20 Quantile is 1.0\n",
            "30 Quantile is 2.0\n",
            "40 Quantile is 2.0\n",
            "50 Quantile is 3.0\n",
            "60 Quantile is 3.0\n",
            "70 Quantile is 5.0\n",
            "80 Quantile is 6.0\n",
            "90 Quantile is 9.0\n",
            "100 Quantile is 111.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english\n",
        "for i in np.arange(0.9,1.01,0.01):\n",
        "    print('{0} Quantile is {1}'.format(int(i*100),np.quantile(df.english_len, i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ5S-j2sFGqj",
        "outputId": "cac3efe7-95ab-416e-a810-1ec3593a44a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90 Quantile is 9.0\n",
            "91 Quantile is 9.0\n",
            "92 Quantile is 10.0\n",
            "93 Quantile is 10.0\n",
            "94 Quantile is 11.0\n",
            "95 Quantile is 11.0\n",
            "96 Quantile is 12.0\n",
            "97 Quantile is 14.0\n",
            "98 Quantile is 17.0\n",
            "99 Quantile is 24.0\n",
            "100 Quantile is 111.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hindi\n",
        "for i in np.arange(0.1,1.1,0.1):\n",
        "    print('{0} Quantile is {1}'.format(int(i*100),np.quantile(df.hindi_len, i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaL2QvImG1Uw",
        "outputId": "a97cc589-72c9-46d4-9d8c-4a4ab86a6ad2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Quantile is 1.0\n",
            "20 Quantile is 1.0\n",
            "30 Quantile is 2.0\n",
            "40 Quantile is 2.0\n",
            "50 Quantile is 3.0\n",
            "60 Quantile is 3.0\n",
            "70 Quantile is 4.0\n",
            "80 Quantile is 6.0\n",
            "90 Quantile is 8.0\n",
            "100 Quantile is 110.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hindi\n",
        "for i in np.arange(0.9,1.01,0.01):\n",
        "    print('{0} Quantile is {1}'.format(int(i*100),np.quantile(df.hindi_len, i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elZFJF4OFGoU",
        "outputId": "46e168f7-c5a5-4570-a3d5-93edd1e61ffe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90 Quantile is 8.0\n",
            "91 Quantile is 9.0\n",
            "92 Quantile is 9.0\n",
            "93 Quantile is 10.0\n",
            "94 Quantile is 10.0\n",
            "95 Quantile is 11.0\n",
            "96 Quantile is 12.0\n",
            "97 Quantile is 14.0\n",
            "98 Quantile is 16.0\n",
            "99 Quantile is 23.0\n",
            "100 Quantile is 110.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For both we only those data who has less than or euqal to 10"
      ],
      "metadata": {
        "id": "JGXOwBbuHAvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.english_len<=10]\n",
        "df = df[df.hindi_len<=10]\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bilAgA5yFGlm",
        "outputId": "47b031c4-2aed-4f61-bafb-86e15cc18ae2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46103, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['hi_inp'] = '<start> ' + df.hindi\n",
        "df['hi_out'] = df.hindi + ' <end>'"
      ],
      "metadata": {
        "id": "XMZEP37OIfIR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['english_len','hindi_len', 'hindi'],inplace=True)"
      ],
      "metadata": {
        "id": "nOmA_P3CIHjB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "diLUzMOXIGZT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking shape\n",
        "print(train.shape, validation.shape)\n",
        "\n",
        "# add <end> in first row so we can use same tokenizer for both hi_inp and eng_out\n",
        "train.hi_inp.iloc[0]= str(train.hi_inp.iloc[0]) + ' <end>'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rXyCQQVFGjQ",
        "outputId": "48b09af0-0a08-4df3-ced5-69ef46755ca9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36882, 3) (9221, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "OHaAXAJna3Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "GM0_vq0SFGgi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization on data\n",
        "token_eng = Tokenizer()\n",
        "token_eng.fit_on_texts(train['english'].values)\n",
        "token_hi = Tokenizer(filters='')\n",
        "token_hi.fit_on_texts(train['hi_inp'].values)"
      ],
      "metadata": {
        "id": "vTFuriOIHzWX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_eng=len(token_eng.word_index.keys())\n",
        "print('Vocab size of english is',vocab_size_eng)\n",
        "vocab_size_hi=len(token_hi.word_index.keys())\n",
        "print('Vocab size of hindi is',vocab_size_hi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZgnTxMNHzTh",
        "outputId": "e24730ef-288b-4a87-db85-012a7586c370"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of english is 3106\n",
            "Vocab size of hindi is 3317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_hi.word_index['<start>'], token_hi.word_index['<end>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzlVWxtkHzRA",
        "outputId": "54e6c829-1506-4b72-995c-c4bdf0e5bc27"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2979)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text to numbers\n",
        "train_dec_in = token_hi.texts_to_sequences(train.hi_inp)\n",
        "train_hi_inp = token_eng.texts_to_sequences(train.english)"
      ],
      "metadata": {
        "id": "2H8sKo43HzO5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 10\n",
        "# test to sequence\n",
        "train_dec_in = token_hi.texts_to_sequences(train.hi_inp)\n",
        "train_dec_out = token_hi.texts_to_sequences(train.hi_out)\n",
        "train_eng_inp = token_eng.texts_to_sequences(train.english)\n",
        "\n",
        "# padding\n",
        "train_dec_in_seq = pad_sequences(train_dec_in, maxlen=max_len, padding='post', dtype='int32')\n",
        "train_dec_out_seq = pad_sequences(train_dec_out, maxlen=max_len, padding='post', dtype='int32')\n",
        "train_eng_inp_seq = pad_sequences(train_eng_inp, maxlen=max_len, padding='post', dtype='int32')\n",
        "\n",
        "# test to sequence\n",
        "test_dec_in = token_hi.texts_to_sequences(validation.hi_inp)\n",
        "test_dec_out = token_hi.texts_to_sequences(validation.hi_out)\n",
        "test_eng_inp = token_eng.texts_to_sequences(validation.english)\n",
        "\n",
        "# padding\n",
        "test_dec_in_seq = pad_sequences(test_dec_in, maxlen=max_len, padding='post', dtype='int32')\n",
        "test_dec_out_seq = pad_sequences(test_dec_out, maxlen=max_len, padding='post', dtype='int32')\n",
        "test_eng_inp_seq = pad_sequences(test_eng_inp, maxlen=max_len, padding='post', dtype='int32')"
      ],
      "metadata": {
        "id": "SCX5napvLBUp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_input_length, dec_input_length, dec_out_length = 10,10,10"
      ],
      "metadata": {
        "id": "ZokjgB8bLZQG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "print('Encoder text :',train.english.iloc[index])\n",
        "print('Representation :',train_eng_inp_seq[index])\n",
        "\n",
        "print('hi text :', train.hi_inp.iloc[index])\n",
        "print('Decoder input :',train_dec_in_seq[index])\n",
        "\n",
        "print('Decoder output :',train.hi_out.iloc[index])\n",
        "print('Decoder output :',train_dec_out_seq[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlNlodTRLmhy",
        "outputId": "7991d1a5-018d-4a26-da4a-dba4a34b4c47"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder text : alpha object to drive the behaviour\n",
            "Representation : [ 331  141    2  224    1 1913    0    0    0    0]\n",
            "hi text : <start> व्यवहार ड्राइव करने के लिए अल्फा ऑब्जेक्ट <end>\n",
            "Decoder input : [   1 1572  226   52    3   11  292  763 2979    0]\n",
            "Decoder output : व्यवहार ड्राइव करने के लिए अल्फा ऑब्जेक्ट <end>\n",
            "Decoder output : [1572  226   52    3   11  292  763 2979    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionaries from num to word and vice versa\n",
        "hi_index_word = {}\n",
        "hi_word_index = {}\n",
        "\n",
        "for key, value in token_hi.word_index.items():\n",
        "    hi_index_word[value] = key\n",
        "    hi_word_index[key] = value"
      ],
      "metadata": {
        "id": "PicMY9qpMDzF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hi_vocab_size = len(token_hi.word_index)+1\n",
        "eng_vocab_size = len(token_eng.word_index)+1\n",
        "\n",
        "print('hindi vocab size',hi_vocab_size)\n",
        "print('english vocab size',eng_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCkpFgxLt9b",
        "outputId": "c11cd2b5-78ba-45de-adee-85abb0e71cb9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hindi vocab size 3318\n",
            "english vocab size 3107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generator"
      ],
      "metadata": {
        "id": "evoiS36vN81K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference : https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
        "\n",
        "def data_generator(encoder_inp, decoder_inp, decoder_out, batch_size):\n",
        "    '''\n",
        "    Data Generator for model training\n",
        "    It returns list of encoder_imput and decoder_input of each shape [batch_size, max_len]\n",
        "    and decoder_out of shape (batch_size, max_len)\n",
        "    '''\n",
        "    while True:\n",
        "        for i in range(0, len(encoder_inp), batch_size):\n",
        "            # creating empty matrix\n",
        "            enc_inp_batch = np.zeros(shape = (batch_size, encoder_inp.shape[-1])) # shape = (batch_size, max_len)\n",
        "            dec_inp_batch = np.zeros(shape = (batch_size, decoder_inp.shape[-1])) # shape = (batch_size, max_len)\n",
        "            dec_out_batch = np.zeros(shape = (batch_size, decoder_out.shape[-1])) # shape = (batch_size, max_len)\n",
        "            for j in range(batch_size):\n",
        "                if (i+j) < len(encoder_inp):\n",
        "                    # adding batch wise values\n",
        "                    enc_inp_batch[j] = encoder_inp[i+j]\n",
        "                    dec_inp_batch[j] = decoder_inp[i+j]\n",
        "                    dec_out_batch[j] = decoder_out[i+j]\n",
        "            # Yield is a keyword in Python that is used to return from a function without\n",
        "            # destroying the states of its local variable and when the function is called,\n",
        "            # the execution starts from the last yield statement.\n",
        "            yield [enc_inp_batch, dec_inp_batch], dec_out_batch"
      ],
      "metadata": {
        "id": "vyWBFP1tL2lY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "ViYGwFOCOCb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Input, Dense, RNN, LSTMCell, Activation, add, concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "NPhfSRNCN8Ae"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder - Decoder Seq-Seq model"
      ],
      "metadata": {
        "id": "OS2UfUDdODzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        super().__init__()\n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = Embedding(inp_vocab_size, embedding_size, input_length = input_length)\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.lstm_size = lstm_size\n",
        "        lstmcell = LSTMCell(lstm_size)\n",
        "        self.lstm = RNN(lstmcell, return_sequences = True, return_state = True)\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        embeddings = self.embedding(input_sequence)\n",
        "\n",
        "        encoder_output, encoder_final_state_h, encoder_final_state_c = self.lstm(embeddings, initial_state = states)\n",
        "\n",
        "        return encoder_output, encoder_final_state_h, encoder_final_state_c\n",
        "\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      '''\n",
        "      return tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))"
      ],
      "metadata": {
        "id": "XFkdLubQOFhq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        #Initialize Embedding layer\n",
        "        self.embed_layer = Embedding(input_dim=out_vocab_size, output_dim=embedding_size, input_length=input_length)\n",
        "        #Intialize Decoder LSTM layer\n",
        "        lstmcell = LSTMCell(lstm_size)\n",
        "        self.lstm_layer = RNN(lstmcell, return_sequences=True, return_state=True)\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "\n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        x = self.embed_layer(input_sequence)\n",
        "        decoder_output,decoder_final_state_h,decoder_final_state_c = self.lstm_layer(x, initial_state = initial_states)\n",
        "        return decoder_output,decoder_final_state_h,decoder_final_state_c"
      ],
      "metadata": {
        "id": "tURlXWydOG0S"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYwO2tMhOIka"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SmHNY69LigTu"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, ita_vocab_size, eng_vocab_size, enc_embedding_size, dec_embedding_size, lstm_size,\n",
        "                 enc_input_length, dec_input_length):\n",
        "        super().__init__()\n",
        "        #Create encoder object\n",
        "        self.encode_obj = Encoder(ita_vocab_size,enc_embedding_size,lstm_size,enc_input_length)\n",
        "        #Create decoder object\n",
        "        self.decode_obj = Decoder(eng_vocab_size,dec_embedding_size,lstm_size,dec_input_length)\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.dense = Dense(eng_vocab_size, activation='softmax')\n",
        "        self.enc_input_length = enc_input_length\n",
        "\n",
        "    def call(self,data):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer\n",
        "\n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        enc_data = data[0]\n",
        "        dec_data = data[1]\n",
        "\n",
        "        # A\n",
        "        enc_initial_state = self.encode_obj.initialize_states(tf.shape(enc_data)[0])\n",
        "        enc_out, enc_h, enc_c = self.encode_obj(enc_data,enc_initial_state)\n",
        "\n",
        "        # B\n",
        "        dec_out, dec_h, dec_c = self.decode_obj(dec_data, [enc_h, enc_c])\n",
        "        # C\n",
        "        x = self.dense(dec_out)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_embedding_size = 50\n",
        "dec_embedding_size = 100\n",
        "lstm_size = 128\n",
        "\n",
        "# defining model\n",
        "en_hi_model = Encoder_decoder(eng_vocab_size, hi_vocab_size, enc_embedding_size, dec_embedding_size, lstm_size,\n",
        "                 enc_input_length, dec_input_length)"
      ],
      "metadata": {
        "id": "5hdSVDcMOKr6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model compile\n",
        "en_hi_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# setting tensorboard\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# directory to save log\n",
        "log_dir='/content/logs/fit/en_hi_model/'\n",
        "\n",
        "# call back of tensorboard\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "callback = [tensorboard_callback, early_stop]"
      ],
      "metadata": {
        "id": "90HsXT0dOQFS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 444\n",
        "# send data to data generators\n",
        "train_data_generator = data_generator(train_eng_inp_seq, train_dec_in_seq, train_dec_out_seq, batch_size)\n",
        "val_data_generator = data_generator(test_eng_inp_seq, test_dec_in_seq, test_dec_out_seq, batch_size)\n",
        "\n",
        "# train model\n",
        "en_hi_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 10, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHzoSeKPOZ_y",
        "outputId": "b67e4e4c-6ae0-4a39-ce12-7cb835c36c55"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "83/83 [==============================] - 36s 307ms/step - loss: 3.9568 - val_loss: 2.4973\n",
            "Epoch 2/10\n",
            "83/83 [==============================] - 4s 48ms/step - loss: 2.3717 - val_loss: 2.1965\n",
            "Epoch 3/10\n",
            "83/83 [==============================] - 5s 66ms/step - loss: 2.1290 - val_loss: 2.0515\n",
            "Epoch 4/10\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 2.0107 - val_loss: 1.9613\n",
            "Epoch 5/10\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 1.9291 - val_loss: 1.8914\n",
            "Epoch 6/10\n",
            "83/83 [==============================] - 5s 58ms/step - loss: 1.8661 - val_loss: 1.8373\n",
            "Epoch 7/10\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 1.8116 - val_loss: 1.7876\n",
            "Epoch 8/10\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 1.7591 - val_loss: 1.7397\n",
            "Epoch 9/10\n",
            "83/83 [==============================] - 6s 73ms/step - loss: 1.7072 - val_loss: 1.6902\n",
            "Epoch 10/10\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 1.6518 - val_loss: 1.6391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f86d7ef1780>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_hi_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 10, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk1ZOnR9OiyH",
        "outputId": "fe60fb34-4643-45bf-f738-ff947157dafd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "83/83 [==============================] - 5s 64ms/step - loss: 1.5991 - val_loss: 1.5903\n",
            "Epoch 2/10\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 1.5453 - val_loss: 1.5425\n",
            "Epoch 3/10\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 1.4959 - val_loss: 1.4950\n",
            "Epoch 4/10\n",
            "83/83 [==============================] - 5s 61ms/step - loss: 1.4451 - val_loss: 1.4484\n",
            "Epoch 5/10\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 1.3953 - val_loss: 1.4026\n",
            "Epoch 6/10\n",
            "83/83 [==============================] - 5s 60ms/step - loss: 1.3464 - val_loss: 1.3573\n",
            "Epoch 7/10\n",
            "83/83 [==============================] - 5s 56ms/step - loss: 1.3001 - val_loss: 1.3140\n",
            "Epoch 8/10\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 1.2509 - val_loss: 1.2720\n",
            "Epoch 9/10\n",
            "83/83 [==============================] - 4s 48ms/step - loss: 1.2034 - val_loss: 1.2314\n",
            "Epoch 10/10\n",
            "83/83 [==============================] - 5s 64ms/step - loss: 1.1593 - val_loss: 1.1909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f863c00d390>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_hi_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 10, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiT3Wx3iBM6J",
        "outputId": "60f87f9b-8c59-4199-c72f-d1b7466ab385"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 1.1142 - val_loss: 1.1508\n",
            "Epoch 2/10\n",
            "83/83 [==============================] - 6s 68ms/step - loss: 1.0707 - val_loss: 1.1109\n",
            "Epoch 3/10\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 1.0245 - val_loss: 1.0651\n",
            "Epoch 4/10\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 0.9787 - val_loss: 1.0251\n",
            "Epoch 5/10\n",
            "83/83 [==============================] - 5s 66ms/step - loss: 0.9355 - val_loss: 0.9861\n",
            "Epoch 6/10\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 0.8949 - val_loss: 0.9489\n",
            "Epoch 7/10\n",
            "83/83 [==============================] - 6s 71ms/step - loss: 0.8549 - val_loss: 0.9149\n",
            "Epoch 8/10\n",
            "83/83 [==============================] - 4s 54ms/step - loss: 0.8177 - val_loss: 0.8801\n",
            "Epoch 9/10\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 0.7818 - val_loss: 0.8463\n",
            "Epoch 10/10\n",
            "83/83 [==============================] - 5s 63ms/step - loss: 0.7465 - val_loss: 0.8149\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f863c02c820>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_hi_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 20, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owHsNYQaBvR6",
        "outputId": "9b9cd153-d750-4eb0-98c5-41d53cb0bfa9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "83/83 [==============================] - 6s 69ms/step - loss: 0.7123 - val_loss: 0.7838\n",
            "Epoch 2/20\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.6782 - val_loss: 0.7525\n",
            "Epoch 3/20\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 0.6479 - val_loss: 0.7211\n",
            "Epoch 4/20\n",
            "83/83 [==============================] - 5s 61ms/step - loss: 0.6147 - val_loss: 0.6898\n",
            "Epoch 5/20\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 0.5827 - val_loss: 0.6610\n",
            "Epoch 6/20\n",
            "83/83 [==============================] - 5s 58ms/step - loss: 0.5515 - val_loss: 0.6330\n",
            "Epoch 7/20\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.5232 - val_loss: 0.6080\n",
            "Epoch 8/20\n",
            "83/83 [==============================] - 4s 45ms/step - loss: 0.4968 - val_loss: 0.5835\n",
            "Epoch 9/20\n",
            "83/83 [==============================] - 5s 55ms/step - loss: 0.4727 - val_loss: 0.5632\n",
            "Epoch 10/20\n",
            "83/83 [==============================] - 5s 55ms/step - loss: 0.4494 - val_loss: 0.5414\n",
            "Epoch 11/20\n",
            "83/83 [==============================] - 4s 45ms/step - loss: 0.4271 - val_loss: 0.5199\n",
            "Epoch 12/20\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 0.4046 - val_loss: 0.5014\n",
            "Epoch 13/20\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.3846 - val_loss: 0.4835\n",
            "Epoch 14/20\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.3652 - val_loss: 0.4635\n",
            "Epoch 15/20\n",
            "83/83 [==============================] - 5s 57ms/step - loss: 0.3474 - val_loss: 0.4491\n",
            "Epoch 16/20\n",
            "83/83 [==============================] - 5s 55ms/step - loss: 0.3302 - val_loss: 0.4327\n",
            "Epoch 17/20\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 0.3140 - val_loss: 0.4199\n",
            "Epoch 18/20\n",
            "83/83 [==============================] - 6s 76ms/step - loss: 0.2997 - val_loss: 0.4051\n",
            "Epoch 19/20\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 0.2851 - val_loss: 0.3922\n",
            "Epoch 20/20\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.2730 - val_loss: 0.3822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f863c09a380>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_hi_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 30, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M50bj_WXCnyd",
        "outputId": "e675313c-9b85-45f6-cc5a-2fb42f1904c5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "83/83 [==============================] - 4s 48ms/step - loss: 0.2601 - val_loss: 0.3682\n",
            "Epoch 2/30\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 0.2479 - val_loss: 0.3585\n",
            "Epoch 3/30\n",
            "83/83 [==============================] - 5s 56ms/step - loss: 0.2374 - val_loss: 0.3502\n",
            "Epoch 4/30\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 0.2269 - val_loss: 0.3393\n",
            "Epoch 5/30\n",
            "83/83 [==============================] - 4s 54ms/step - loss: 0.2171 - val_loss: 0.3321\n",
            "Epoch 6/30\n",
            "83/83 [==============================] - 5s 61ms/step - loss: 0.2092 - val_loss: 0.3205\n",
            "Epoch 7/30\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.2008 - val_loss: 0.3147\n",
            "Epoch 8/30\n",
            "83/83 [==============================] - 5s 57ms/step - loss: 0.1942 - val_loss: 0.3113\n",
            "Epoch 9/30\n",
            "83/83 [==============================] - 5s 57ms/step - loss: 0.1864 - val_loss: 0.3030\n",
            "Epoch 10/30\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 0.1773 - val_loss: 0.2937\n",
            "Epoch 11/30\n",
            "83/83 [==============================] - 5s 58ms/step - loss: 0.1704 - val_loss: 0.2888\n",
            "Epoch 12/30\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.1639 - val_loss: 0.2817\n",
            "Epoch 13/30\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 0.1572 - val_loss: 0.2763\n",
            "Epoch 14/30\n",
            "83/83 [==============================] - 5s 59ms/step - loss: 0.1514 - val_loss: 0.2724\n",
            "Epoch 15/30\n",
            "83/83 [==============================] - 6s 69ms/step - loss: 0.1459 - val_loss: 0.2663\n",
            "Epoch 16/30\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.1411 - val_loss: 0.2621\n",
            "Epoch 17/30\n",
            "83/83 [==============================] - 5s 63ms/step - loss: 0.1354 - val_loss: 0.2574\n",
            "Epoch 18/30\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.1309 - val_loss: 0.2518\n",
            "Epoch 19/30\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.1265 - val_loss: 0.2490\n",
            "Epoch 20/30\n",
            "83/83 [==============================] - 6s 68ms/step - loss: 0.1225 - val_loss: 0.2473\n",
            "Epoch 21/30\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.1187 - val_loss: 0.2425\n",
            "Epoch 22/30\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.1160 - val_loss: 0.2393\n",
            "Epoch 23/30\n",
            "83/83 [==============================] - 6s 69ms/step - loss: 0.1127 - val_loss: 0.2381\n",
            "Epoch 24/30\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.1086 - val_loss: 0.2358\n",
            "Epoch 25/30\n",
            "83/83 [==============================] - 4s 47ms/step - loss: 0.1058 - val_loss: 0.2309\n",
            "Epoch 26/30\n",
            "83/83 [==============================] - 5s 63ms/step - loss: 0.1026 - val_loss: 0.2274\n",
            "Epoch 27/30\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.0991 - val_loss: 0.2257\n",
            "Epoch 28/30\n",
            "83/83 [==============================] - 4s 46ms/step - loss: 0.0964 - val_loss: 0.2225\n",
            "Epoch 29/30\n",
            "83/83 [==============================] - 6s 70ms/step - loss: 0.0937 - val_loss: 0.2231\n",
            "Epoch 30/30\n",
            "83/83 [==============================] - 4s 45ms/step - loss: 0.0912 - val_loss: 0.2200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f863c0c40a0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_hi_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZMGOdDNQ9He",
        "outputId": "22d4f602-0437-40ad-a42f-80bfab18071b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  246998    \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  449048    \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  428022    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1124068 (4.29 MB)\n",
            "Trainable params: 1124068 (4.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: query resolution aaic team\n",
        "def predict(input_sentence):\n",
        "\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "            predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "            pass the predicted_out to the dense layer\n",
        "            update the states=[state_h,state_c]\n",
        "            And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "            Update the input_to_decoder with current predictions\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "    # A\n",
        "    # lets tokenize the sentence first\n",
        "    tokenized_encoder_input = token_eng.texts_to_sequences([input_sentence])\n",
        "    # padding the sequence\n",
        "    encoder_input = pad_sequences(tokenized_encoder_input, maxlen=max_len, padding='post', dtype='int32')\n",
        "\n",
        "    # B\n",
        "    # get the initial encoder states\n",
        "    enc_init_states = en_hi_model.layers[0].initialize_states(1)\n",
        "    enc_out, enc_h_state, enc_c_state = en_hi_model.layers[0](encoder_input, states = enc_init_states)\n",
        "\n",
        "    # C\n",
        "    decoder_initial_states = [enc_h_state, enc_c_state]\n",
        "    decoder_initial_input = np.zeros((1,1))\n",
        "    decoder_initial_input[0,0] = hi_word_index['<start>']\n",
        "\n",
        "    # D\n",
        "    predicted_words = []\n",
        "    predicting = True\n",
        "    while predicting:\n",
        "\n",
        "        dec_out, dec_h_state, dec_c_state = en_hi_model.layers[1](decoder_initial_input, decoder_initial_states)\n",
        "        english_predicted_int = np.argmax(en_hi_model.layers[2](dec_out).numpy().ravel())\n",
        "        predicted_words.append(english_predicted_int)\n",
        "        # replacing the next input to decoder with current decoder output\n",
        "        decoder_initial_input[0,0] = english_predicted_int\n",
        "        # replacing next decoder initial states with current decoder output states\n",
        "        decoder_initial_states = [dec_h_state, dec_c_state]\n",
        "\n",
        "        # end condition\n",
        "        if english_predicted_int == hi_word_index['<end>'] or len(predicted_words) >= 20:\n",
        "            break\n",
        "\n",
        "    # F\n",
        "    # remove <end> from end\n",
        "    predicted_words = predicted_words[:-1]\n",
        "    return ' '.join([hi_index_word.get(ele, '') for ele in predicted_words])"
      ],
      "metadata": {
        "id": "ZQyjiwHQSKAL"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "from nltk.translate import bleu\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_score = []\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# sampling 1000 datapoints randomly from test set\n",
        "for index, (_, row) in enumerate(train.sample(1000).iterrows()):\n",
        "    input_sent = row.english\n",
        "    predicted_eng = predict(input_sent)\n",
        "    actual_eng = row.hi_out.replace('<end>','').strip()\n",
        "\n",
        "    # printing Translation Pairs\n",
        "    if (index + 1)%100 == 0:\n",
        "        print(f\"\\English sentence: {input_sent}\")\n",
        "        print(f\"Actual Translation: {actual_eng}\")\n",
        "        print(f\"Predicted Translation: {predicted_eng}\\n\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    bleu_score.append(sentence_bleu([actual_eng.split(),], predicted_eng.split()))\n",
        "\n",
        "print(f\"Mean Bleu Score = {np.mean(bleu_score)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyWXDycPSy-C",
        "outputId": "5b907911-e36c-492d-82a8-89bf6db4e650"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\English sentence: install module\n",
            "Actual Translation: प्रविष्ट करें\n",
            "Predicted Translation: संस्थापित करें मोड्यूल\n",
            "\n",
            "==================================================\n",
            "\\English sentence: the number of rows the widget should span\n",
            "Actual Translation: कतार की संख्या जिसमें विजेट स्पैन करना चाहिए\n",
            "Predicted Translation: कतार की संख्या जिसमें विजेट स्पैन करना चाहिए\n",
            "\n",
            "==================================================\n",
            "\\English sentence: find symbol\n",
            "Actual Translation: ढूंढें प्रतीक\n",
            "Predicted Translation: ढूंढें प्रतीक\n",
            "\n",
            "==================================================\n",
            "\\English sentence: about\n",
            "Actual Translation: परिचय\n",
            "Predicted Translation: के बारे में\n",
            "\n",
            "==================================================\n",
            "\\English sentence: cd successfully copied\n",
            "Actual Translation: सीडी सफलतापूर्वक कॉपी किया गया\n",
            "Predicted Translation: सीडी सफलतापूर्वक कॉपी किया गया\n",
            "\n",
            "==================================================\n",
            "\\English sentence: align axis\n",
            "Actual Translation: अक्ष संरेखित करें\n",
            "Predicted Translation: अक्ष संरेखित करें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: your project has not been saved\n",
            "Actual Translation: आपकी परियोजना सहेजी गई है\n",
            "Predicted Translation: आपकी परियोजना सहेजी गई है\n",
            "\n",
            "==================================================\n",
            "\\English sentence: data could not be written s\n",
            "Actual Translation: आँकड़ा लिखा नहीं जा सका\n",
            "Predicted Translation: आँकड़ा लिखा नहीं जा सका\n",
            "\n",
            "==================================================\n",
            "\\English sentence: detaching the process…\n",
            "Actual Translation: नहीं\n",
            "Predicted Translation: नहीं\n",
            "\n",
            "==================================================\n",
            "\\English sentence: plugins\n",
            "Actual Translation: प्लगइन्स\n",
            "Predicted Translation: प्लगइन्स\n",
            "\n",
            "==================================================\n",
            "Mean Bleu Score = 0.2640180071004704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention models"
      ],
      "metadata": {
        "id": "Bv-H4YMCaG9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
        "        super().__init__()\n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = Embedding(inp_vocab_size, embedding_size, input_length=input_length)\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.lstm_size = lstm_size\n",
        "        lstmcell = LSTMCell(lstm_size)\n",
        "        self.lstm = RNN(lstmcell, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, input_sequence, states):\n",
        "        '''\n",
        "            This function takes a sequence input and the initial states of the encoder.\n",
        "            Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "            returns -- All encoder_outputs, last time steps hidden and cell state\n",
        "        '''\n",
        "        embed = self.embedding(input_sequence)\n",
        "        enc_out, enc_h, enc_c = self.lstm(embed, initial_state=states)\n",
        "        return enc_out, enc_h, enc_c\n",
        "\n",
        "    def initialize_states(self, batch_size):\n",
        "        '''\n",
        "            Given a batch size it will return intial hidden state and intial cell state.\n",
        "        '''\n",
        "        # we require tensor if we return numpy array it gives error\n",
        "        return tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))"
      ],
      "metadata": {
        "id": "M4aJgUOgSy7t"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "    '''\n",
        "        Class that calculates similarity score based on the scoring_function using Bahdanu attention mechanism.\n",
        "    '''\n",
        "    def __init__(self,scoring_function, att_units):\n",
        "        # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "        super().__init__()\n",
        "        self.scoring_function = scoring_function\n",
        "        if scoring_function == 'concat':\n",
        "            # Intialize variables needed for Concat score function here\n",
        "            # add dense layer for finding w1, w2 and V\n",
        "            self.tanh_activation = Activation('tanh')\n",
        "            self.dense_concat_1 = Dense(att_units)\n",
        "            self.dense_concat_2 = Dense(att_units)\n",
        "            self.dense_1 = Dense(1)\n",
        "        elif scoring_function == 'general':\n",
        "            # Intialize variables needed for General score function here\n",
        "            self.dense_general = Dense(att_units)\n",
        "\n",
        "    def call(self,decoder_hidden_state,encoder_output):\n",
        "        '''\n",
        "            Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "            * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "            Multiply the score function with your encoder_outputs to get the context vector.\n",
        "            Function returns context vector and attention weights(softmax - scores)\n",
        "        '''\n",
        "        if self.scoring_function == 'dot':\n",
        "            # Implement Dot score function here\n",
        "            # decoder_hidden_state = (16, 32)\n",
        "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state, -1)\n",
        "            # decoder_hidden_state = (16, 32, 1)\n",
        "            # mul encoder = (16, 10, 32) and (16, 32, 1)\n",
        "            alpha = tf.matmul(encoder_output, decoder_hidden_state)\n",
        "            # we get alpha of shape (16, 10, 1)\n",
        "\n",
        "        elif self.scoring_function == 'concat':\n",
        "            # tanh((Hd(t-1) * W1 + He(t=n) * W2)) * V\n",
        "            # Implement General score function here\n",
        "            transformed_enc_out = self.dense_concat_1(encoder_output)\n",
        "            transformed_dec_hidden_state = self.dense_concat_2(decoder_hidden_state)\n",
        "\n",
        "            added_both = add([transformed_enc_out, tf.expand_dims(transformed_dec_hidden_state,1)])\n",
        "            added_both = self.tanh_activation(added_both)\n",
        "            alpha = self.dense_1(added_both)\n",
        "            # we get alpha of shape (16, 10, 1)\n",
        "\n",
        "        elif self.scoring_function == 'general':\n",
        "            # He(n,d) * W (d,d') * Hd(d',1)\n",
        "            # Implement General score function here\n",
        "            # pass encoder (16, 10, 32) to dense layer\n",
        "            transformed_enc_out = self.dense_general(encoder_output)\n",
        "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state, -1)\n",
        "\n",
        "            alpha = tf.matmul(transformed_enc_out, decoder_hidden_state)\n",
        "            # we get alpha of shape (16, 10, 1)\n",
        "\n",
        "        # apply softmax on alphas\n",
        "        alpha = tf.squeeze(alpha, axis = -1)\n",
        "        attention_weights = Activation('softmax')(alpha)\n",
        "        # expand dimension of alpha to do matrix multiplication with encoder\n",
        "        attention_weights = tf.expand_dims(attention_weights, axis = -1)\n",
        "\n",
        "        context_vector = tf.matmul(tf.transpose(encoder_output, perm = [0,2,1]), attention_weights)\n",
        "        # remove extra dimension\n",
        "        context_vector = tf.squeeze(context_vector, axis = -1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "Uu4gZrLdSy4x"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Class for finding translation word by word\n",
        "    '''\n",
        "    def __init__(self, tar_vocab_size, embedding_dim, input_length, dec_units, score_fun, att_units):\n",
        "        super().__init__()\n",
        "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "        self.embedding = Embedding(tar_vocab_size, embedding_dim, input_length=input_length)\n",
        "        lstmcell = LSTMCell(dec_units)\n",
        "        self.lstm = RNN(lstmcell, return_sequences=False, return_state=True)\n",
        "        self.dense = Dense(tar_vocab_size)\n",
        "        self.attention = Attention(score_fun, att_units)\n",
        "\n",
        "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
        "        '''\n",
        "            One step decoder mechanisim step by step:\n",
        "        A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "        B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "        C. Concat the context vector with the step A output\n",
        "        D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "        E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "        F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "        '''\n",
        "        # if this parameters then we get shapes of following\n",
        "        # tar_vocab_size=13\n",
        "        # embedding_dim=12\n",
        "        # input_length=10\n",
        "        # dec_units=16\n",
        "        # att_units=16\n",
        "        # batch_size=32\n",
        "\n",
        "        # A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "        embeddings_input_dec = self.embedding(input_to_decoder)  #shape = (32, 1, 12)\n",
        "\n",
        "        # B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "        context_vector, att_weights = self.attention(state_h, encoder_output)  # context_vector = (32, 16)\n",
        "\n",
        "        # C. Concat the context vector with the step A output\n",
        "        input_to_decoder = concatenate([embeddings_input_dec,tf.expand_dims(context_vector,1)])  #shape = (32, 1, 16)\n",
        "\n",
        "        # D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "        dec_out, dec_h_state, dec_c_state = self.lstm(input_to_decoder, initial_state=[state_h, state_c])\n",
        "\n",
        "        # E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "        predicted_out = self.dense(dec_out)\n",
        "\n",
        "        # output ,state_h ,state_c\n",
        "        # (32, 13) (32, 16) (32, 16)\n",
        "\n",
        "        # F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "        return predicted_out, dec_h_state, dec_c_state, att_weights, context_vector"
      ],
      "metadata": {
        "id": "tqImeIlfSy1y"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_size, input_length, dec_units ,score_fun ,att_units):\n",
        "        #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "        super().__init__()\n",
        "        self.onestepdecoder = One_Step_Decoder(out_vocab_size, embedding_size, input_length, dec_units, score_fun, att_units)\n",
        "\n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        # https://www.tensorflow.org/api_docs/python/tf/TensorArray\n",
        "        all_outputs = tf.TensorArray(tf.float32, size = tf.shape(input_to_decoder)[1])\n",
        "\n",
        "        #Iterate till the length of the decoder input\n",
        "        for i in range(tf.shape(input_to_decoder)[1]):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            output, decoder_hidden_state, decoder_cell_state, attention_weights, context_vector = \\\n",
        "            self.onestepdecoder(input_to_decoder[:,i:i+1], encoder_output,decoder_hidden_state, decoder_cell_state)\n",
        "            # Store the all_outputs in tensorarray\n",
        "            all_outputs = all_outputs.write(i, output)\n",
        "        # Return the tensor\n",
        "        all_outputs = tf.transpose(all_outputs.stack(), perm = [1,0,2])\n",
        "        return all_outputs"
      ],
      "metadata": {
        "id": "13JZFYhqSyzT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    def __init__(self, inp_vocab_size, out_vocab_size, embedding_size, enc_lstm_units, dec_lstm_units, enc_input_length, dec_input_length, \\\n",
        "                 score_fun, att_units):\n",
        "        super().__init__()\n",
        "        #Intializing objects from encoder decoder\n",
        "        self.encoder = Encoder(inp_vocab_size, embedding_size, enc_lstm_units, enc_input_length)\n",
        "        self.decoder = Decoder(out_vocab_size, embedding_size, dec_input_length, dec_lstm_units, score_fun, att_units)\n",
        "\n",
        "    def call(self,data):\n",
        "        encoder_inputs = data[0]\n",
        "        decoder_inputs = data[1]\n",
        "        #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "        encoder_initial_states = self.encoder.initialize_states(tf.shape(encoder_inputs)[0])\n",
        "        enc_out, enc_h_state, enc_c_state = self.encoder(encoder_inputs, encoder_initial_states)\n",
        "        # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "        dec_out = self.decoder(decoder_inputs, enc_out, enc_h_state, enc_c_state)\n",
        "\n",
        "        # return the decoder output\n",
        "        return dec_out"
      ],
      "metadata": {
        "id": "oQjdt5bYaYOq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "4KFKtzOTaaRe"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dot model"
      ],
      "metadata": {
        "id": "__rt7C38bqHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "dot_model = encoder_decoder(inp_vocab_size = eng_vocab_size, out_vocab_size = hi_vocab_size,\n",
        "                            embedding_size = 128, enc_lstm_units = 128, dec_lstm_units = 128,\n",
        "                            enc_input_length = enc_input_length, dec_input_length = dec_input_length,\n",
        "                            score_fun = 'dot', att_units = 128)\n",
        "#compiling the model\n",
        "dot_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = loss_function)\n",
        "\n",
        "# callbacks\n",
        "# EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# setting tensorboard\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# directory to save log\n",
        "log_dir='/content/logs/fit/dot_model/'\n",
        "\n",
        "# call back of tensorboard\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "callback = [tensorboard_callback, early_stop]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbD_PgXwabx3",
        "outputId": "e8db83b0-9987-4125-d895-8ef090281214"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 224\n",
        "# send data to data generators\n",
        "train_data_generator = data_generator(train_eng_inp_seq, train_dec_in_seq, train_dec_out_seq, batch_size)\n",
        "val_data_generator = data_generator(test_eng_inp_seq, test_dec_in_seq, test_dec_out_seq, batch_size)\n",
        "\n",
        "# model training\n",
        "dot_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 10, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bgfkzumady9",
        "outputId": "64c536ac-cdc8-4f4f-ce34-d1883e44f333"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "164/164 [==============================] - 24s 114ms/step - loss: 2.2284 - val_loss: 2.0606\n",
            "Epoch 2/10\n",
            "164/164 [==============================] - 14s 86ms/step - loss: 1.9970 - val_loss: 1.8433\n",
            "Epoch 3/10\n",
            "164/164 [==============================] - 14s 84ms/step - loss: 1.7569 - val_loss: 1.6094\n",
            "Epoch 4/10\n",
            "164/164 [==============================] - 13s 79ms/step - loss: 1.5323 - val_loss: 1.4196\n",
            "Epoch 5/10\n",
            "164/164 [==============================] - 13s 81ms/step - loss: 1.3271 - val_loss: 1.2280\n",
            "Epoch 6/10\n",
            "164/164 [==============================] - 13s 80ms/step - loss: 1.1308 - val_loss: 1.0553\n",
            "Epoch 7/10\n",
            "164/164 [==============================] - 13s 81ms/step - loss: 0.9461 - val_loss: 0.8904\n",
            "Epoch 8/10\n",
            "164/164 [==============================] - 15s 93ms/step - loss: 0.7761 - val_loss: 0.7456\n",
            "Epoch 9/10\n",
            "164/164 [==============================] - 14s 85ms/step - loss: 0.6311 - val_loss: 0.6270\n",
            "Epoch 10/10\n",
            "164/164 [==============================] - 14s 85ms/step - loss: 0.5135 - val_loss: 0.5326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f86ddad9960>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "dot_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 35, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5yhssswDxqr",
        "outputId": "b5f0db33-e595-4677-c0e4-19b73824f70a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "164/164 [==============================] - 15s 89ms/step - loss: 0.4187 - val_loss: 0.4585\n",
            "Epoch 2/35\n",
            "164/164 [==============================] - 14s 85ms/step - loss: 0.3443 - val_loss: 0.3951\n",
            "Epoch 3/35\n",
            "164/164 [==============================] - 14s 82ms/step - loss: 0.2855 - val_loss: 0.3467\n",
            "Epoch 4/35\n",
            "164/164 [==============================] - 15s 90ms/step - loss: 0.2389 - val_loss: 0.3078\n",
            "Epoch 5/35\n",
            "164/164 [==============================] - 14s 88ms/step - loss: 0.2032 - val_loss: 0.2783\n",
            "Epoch 6/35\n",
            "164/164 [==============================] - 14s 86ms/step - loss: 0.1726 - val_loss: 0.2563\n",
            "Epoch 7/35\n",
            "164/164 [==============================] - 13s 79ms/step - loss: 0.1508 - val_loss: 0.2356\n",
            "Epoch 8/35\n",
            "164/164 [==============================] - 15s 88ms/step - loss: 0.1325 - val_loss: 0.2235\n",
            "Epoch 9/35\n",
            "164/164 [==============================] - 13s 78ms/step - loss: 0.1164 - val_loss: 0.2118\n",
            "Epoch 10/35\n",
            "164/164 [==============================] - 14s 88ms/step - loss: 0.1045 - val_loss: 0.1997\n",
            "Epoch 11/35\n",
            "164/164 [==============================] - 13s 80ms/step - loss: 0.0944 - val_loss: 0.1937\n",
            "Epoch 12/35\n",
            "164/164 [==============================] - 15s 92ms/step - loss: 0.0854 - val_loss: 0.1863\n",
            "Epoch 13/35\n",
            "164/164 [==============================] - 14s 87ms/step - loss: 0.0773 - val_loss: 0.1806\n",
            "Epoch 14/35\n",
            "164/164 [==============================] - 13s 80ms/step - loss: 0.0717 - val_loss: 0.1771\n",
            "Epoch 15/35\n",
            "164/164 [==============================] - 13s 79ms/step - loss: 0.0666 - val_loss: 0.1740\n",
            "Epoch 16/35\n",
            "164/164 [==============================] - 13s 78ms/step - loss: 0.0615 - val_loss: 0.1709\n",
            "Epoch 17/35\n",
            "164/164 [==============================] - 13s 76ms/step - loss: 0.0574 - val_loss: 0.1682\n",
            "Epoch 18/35\n",
            "164/164 [==============================] - 14s 82ms/step - loss: 0.0545 - val_loss: 0.1653\n",
            "Epoch 19/35\n",
            "164/164 [==============================] - 13s 80ms/step - loss: 0.0507 - val_loss: 0.1635\n",
            "Epoch 20/35\n",
            "164/164 [==============================] - 13s 79ms/step - loss: 0.0478 - val_loss: 0.1618\n",
            "Epoch 21/35\n",
            "164/164 [==============================] - 17s 103ms/step - loss: 0.0456 - val_loss: 0.1626\n",
            "Epoch 22/35\n",
            "164/164 [==============================] - 15s 90ms/step - loss: 0.0437 - val_loss: 0.1619\n",
            "Epoch 23/35\n",
            "164/164 [==============================] - 15s 91ms/step - loss: 0.0419 - val_loss: 0.1624\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f870189f1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0_gNuFmalAF",
        "outputId": "19ee389a-7487-4548-ab50-0920be7ad43b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  529280    \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  1049846   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1579126 (6.02 MB)\n",
            "Trainable params: 1579126 (6.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "def plot_attention(attention, encoder_inp, predicted):\n",
        "    heatmap_df = pd.DataFrame(attention, columns=encoder_inp, index=predicted)\n",
        "    plt.figure(figsize=(7, 10))\n",
        "    sns.heatmap(heatmap_df, cmap='YlGnBu', linewidths=.3)\n",
        "    plt.title(\"Attention Plot\")\n",
        "    plt.ylabel(\"English\")\n",
        "    plt.xlabel(\"Hindi\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "c88DYNNRavzD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_attention(input_sentence, model, plot_attention_weights = False):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "            predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "            Save the attention weights\n",
        "            And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "    # A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    # tokenization of the sentence\n",
        "    tokenized_encoder_input = token_eng.texts_to_sequences([input_sentence])\n",
        "    # padding the sequence\n",
        "    encoder_input = pad_sequences(tokenized_encoder_input, maxlen=max_len, padding='post')\n",
        "\n",
        "    # B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    enc_init_states = model.layers[0].initialize_states(1)\n",
        "    enc_out, enc_h_state, enc_c_state = model.layers[0](encoder_input, states = enc_init_states)\n",
        "    # initializing decoder states\n",
        "    decoder_h_state = enc_h_state\n",
        "    decoder_c_state = enc_c_state\n",
        "\n",
        "    # C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    # decoder initial input\n",
        "    decoder_initial_input = np.zeros((1,1))\n",
        "    decoder_initial_input[0,0] = hi_word_index['<start>']\n",
        "\n",
        "    # D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "    predicted_words = []\n",
        "    att_weights_all = []\n",
        "    predicting = True\n",
        "    while predicting:\n",
        "        # predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "        prediction, decoder_h_state, decoder_c_state, att_weights,_ = model.layers[1].onestepdecoder(decoder_initial_input,\n",
        "                                                                                                                  enc_out,\n",
        "                                                                                                                  decoder_h_state,\n",
        "                                                                                                                  decoder_c_state)\n",
        "        #predicted english token\n",
        "        english_predicted_int = np.argmax(prediction.numpy().ravel())\n",
        "        predicted_words.append(english_predicted_int)\n",
        "\n",
        "        # Save the attention weights\n",
        "        att_weights_all.append(att_weights.numpy().ravel())\n",
        "        decoder_initial_input[0,0] = english_predicted_int\n",
        "        # break condition\n",
        "        if english_predicted_int == hi_word_index['<end>'] or len(predicted_words)>=20:\n",
        "            break\n",
        "\n",
        "    #checking for non-padding words in encoder input\n",
        "    att_weights_all = np.array(att_weights_all)\n",
        "    non_padded_encoder_input = np.where(encoder_input[0] != 0)[0]\n",
        "    encoder_input_words = np.array(input_sentence.split())[non_padded_encoder_input]\n",
        "    # get the word using the tokenizer(word index) and then store it in a string.\n",
        "    decoder_output_words = [hi_index_word.get(ele, '') for ele in predicted_words]\n",
        "    #keeping only those attention weights corresponding to non-padded words\n",
        "    att_weights_all = att_weights_all[:,non_padded_encoder_input]\n",
        "\n",
        "    # E. Call plot_attention(#params)\n",
        "    if plot_attention_weights:\n",
        "        plot_attention(att_weights_all, encoder_input_words, decoder_output_words)\n",
        "    else:\n",
        "        # F. Return the predicted sentence\n",
        "        return ' '.join(decoder_output_words)"
      ],
      "metadata": {
        "id": "lO3uw5_3ayNG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_score = []\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# sampling 1000 datapoints randomly from test set\n",
        "for index, (_, row) in enumerate(train.sample(1000).iterrows()):\n",
        "    input_sent = row.english\n",
        "    predicted_eng = predict_attention(input_sent, dot_model, plot_attention_weights = False)\n",
        "    actual_eng = row.hi_out.replace('<end>','').strip()\n",
        "    predicted_eng = predicted_eng.replace('<end>','').strip()\n",
        "\n",
        "    # printing Translation Pairs\n",
        "    if (index + 1)%100 == 0:\n",
        "        print(f\"\\English sentence: {input_sent}\")\n",
        "        print(f\"Actual Translation: {actual_eng}\")\n",
        "        print(f\"Predicted Translation: {predicted_eng}\\n\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    bleu_score.append(sentence_bleu([actual_eng.split(),], predicted_eng.split()))\n",
        "\n",
        "print(f\"Mean Bleu Score = {np.mean(bleu_score)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj8-7Rqqa-N2",
        "outputId": "7169b00e-47c0-4f8b-caf2-57cab495cd6b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\\English sentence: gnome solitaire\n",
            "Actual Translation: गनोम सॉलिटेयर\n",
            "Predicted Translation: गनोम सॉलिटेयर\n",
            "\n",
            "==================================================\n",
            "\\English sentence: about\n",
            "Actual Translation: के बारे में\n",
            "Predicted Translation: के बारे में\n",
            "\n",
            "==================================================\n",
            "\\English sentence: d ata project\n",
            "Actual Translation: डेटा परियोजना\n",
            "Predicted Translation: डेटा परियोजना\n",
            "\n",
            "==================================================\n",
            "\\English sentence: edit as script\n",
            "Actual Translation: संपादन जैसे स्क्रिप्ट\n",
            "Predicted Translation: संपादन जैसे स्क्रिप्ट\n",
            "\n",
            "==================================================\n",
            "\\English sentence: tag de claration\n",
            "Actual Translation: टैग\n",
            "Predicted Translation: टैग\n",
            "\n",
            "==================================================\n",
            "\\English sentence: shortcut\n",
            "Actual Translation: शॉर्टकटः\n",
            "Predicted Translation: शॉर्टकट\n",
            "\n",
            "==================================================\n",
            "\\English sentence: discard changes\n",
            "Actual Translation: बदलाव त्यागें\n",
            "Predicted Translation: बदलाव त्यागें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: the type of subpixel antialiasing none rgb bgr vrgb vbgr\n",
            "Actual Translation: उपपिक्सेल एंटीएलियासिंग का प्रकार कोई नहीं\n",
            "Predicted Translation: उपपिक्सेल एंटीएलियासिंग का प्रकार कोई नहीं\n",
            "\n",
            "==================================================\n",
            "\\English sentence: mmm d\n",
            "Actual Translation: \n",
            "Predicted Translation: \n",
            "\n",
            "==================================================\n",
            "\\English sentence: try rearranging the cards\n",
            "Actual Translation: ताश को फिर से जमाने की कोशिश करें\n",
            "Predicted Translation: ताश को फिर से जमाने की कोशिश करें\n",
            "\n",
            "==================================================\n",
            "Mean Bleu Score = 0.285709518524999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General Model"
      ],
      "metadata": {
        "id": "SCCiuVwSD8TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "tf.keras.backend.clear_session()\n",
        "general_model = encoder_decoder(inp_vocab_size = eng_vocab_size, out_vocab_size = hi_vocab_size,\n",
        "                            embedding_size = 128, enc_lstm_units = 128, dec_lstm_units = 128,\n",
        "                            enc_input_length = enc_input_length, dec_input_length = dec_input_length,\n",
        "                            score_fun = 'general', att_units = 128)\n",
        "#compiling the model\n",
        "general_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = loss_function)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# setting tensorboard\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# directory to save log\n",
        "log_dir='/content/logs/fit/general_model/'\n",
        "\n",
        "# call back of tensorboard\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "callback = [tensorboard_callback, early_stop]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAGjB_09cVWV",
        "outputId": "deef7e2a-ee24-4e2b-9d6d-14e827604072"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "general_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 20, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8WSMr4PED1K",
        "outputId": "8e91f5a0-d083-4eae-8dfe-7f3dbf4e3213"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "164/164 [==============================] - 27s 129ms/step - loss: 2.2303 - val_loss: 2.0551\n",
            "Epoch 2/20\n",
            "164/164 [==============================] - 15s 91ms/step - loss: 2.0077 - val_loss: 1.8363\n",
            "Epoch 3/20\n",
            "164/164 [==============================] - 15s 91ms/step - loss: 1.7420 - val_loss: 1.5906\n",
            "Epoch 4/20\n",
            "164/164 [==============================] - 15s 92ms/step - loss: 1.5138 - val_loss: 1.3959\n",
            "Epoch 5/20\n",
            "164/164 [==============================] - 15s 92ms/step - loss: 1.3116 - val_loss: 1.2196\n",
            "Epoch 6/20\n",
            "164/164 [==============================] - 15s 91ms/step - loss: 1.1231 - val_loss: 1.0529\n",
            "Epoch 7/20\n",
            "164/164 [==============================] - 17s 102ms/step - loss: 0.9436 - val_loss: 0.8925\n",
            "Epoch 8/20\n",
            "164/164 [==============================] - 17s 104ms/step - loss: 0.7756 - val_loss: 0.7488\n",
            "Epoch 9/20\n",
            "164/164 [==============================] - 15s 93ms/step - loss: 0.6296 - val_loss: 0.6291\n",
            "Epoch 10/20\n",
            "164/164 [==============================] - 15s 90ms/step - loss: 0.5083 - val_loss: 0.5293\n",
            "Epoch 11/20\n",
            "164/164 [==============================] - 15s 89ms/step - loss: 0.4136 - val_loss: 0.4492\n",
            "Epoch 12/20\n",
            "164/164 [==============================] - 15s 92ms/step - loss: 0.3397 - val_loss: 0.3881\n",
            "Epoch 13/20\n",
            "164/164 [==============================] - 15s 94ms/step - loss: 0.2812 - val_loss: 0.3412\n",
            "Epoch 14/20\n",
            "164/164 [==============================] - 15s 92ms/step - loss: 0.2339 - val_loss: 0.3043\n",
            "Epoch 15/20\n",
            "164/164 [==============================] - 15s 93ms/step - loss: 0.1982 - val_loss: 0.2735\n",
            "Epoch 16/20\n",
            "164/164 [==============================] - 16s 99ms/step - loss: 0.1713 - val_loss: 0.2503\n",
            "Epoch 17/20\n",
            "164/164 [==============================] - 16s 96ms/step - loss: 0.1478 - val_loss: 0.2294\n",
            "Epoch 18/20\n",
            "164/164 [==============================] - 15s 90ms/step - loss: 0.1276 - val_loss: 0.2157\n",
            "Epoch 19/20\n",
            "164/164 [==============================] - 15s 93ms/step - loss: 0.1133 - val_loss: 0.2043\n",
            "Epoch 20/20\n",
            "164/164 [==============================] - 15s 92ms/step - loss: 0.1018 - val_loss: 0.2001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8632225810>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_score = []\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# sampling 1000 datapoints randomly from test set\n",
        "for index, (_, row) in enumerate(train.sample(1000).iterrows()):\n",
        "    input_sent = row.english\n",
        "    predicted_eng = predict_attention(input_sent, general_model, plot_attention_weights = False)\n",
        "    actual_eng = row.hi_out.replace('<end>','').strip()\n",
        "    predicted_eng = predicted_eng.replace('<end>','').strip()\n",
        "\n",
        "    # printing Translation Pairs\n",
        "    if (index + 1)%100 == 0:\n",
        "        print(f\"\\English sentence: {input_sent}\")\n",
        "        print(f\"Actual Translation: {actual_eng}\")\n",
        "        print(f\"Predicted Translation: {predicted_eng}\\n\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    bleu_score.append(sentence_bleu([actual_eng.split(),], predicted_eng.split()))\n",
        "\n",
        "print(f\"Mean Bleu Score = {np.mean(bleu_score)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWNvUW1EN5I",
        "outputId": "e73fe4e9-34f2-432c-a7c2-32201cc72fc5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\\English sentence: disable all breakpoints\n",
            "Actual Translation: सभी खण्डन बिन्दु अक्षम करें\n",
            "Predicted Translation: सभी खण्डन बिन्दु अक्षम करें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: select files\n",
            "Actual Translation: फ़ाइल चुनें\n",
            "Predicted Translation: फ़ाइल चुनें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: replace selection\n",
            "Actual Translation: बदलें\n",
            "Predicted Translation: बदलें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: move a onto the five of hearts\n",
            "Actual Translation: को एक लाल पान का पंजा पर ले जाएँ\n",
            "Predicted Translation: को एक लाल पान का पंजा पर ले जाएँ\n",
            "\n",
            "==================================================\n",
            "\\English sentence: paragraph\n",
            "Actual Translation: अनुच्छेद\n",
            "Predicted Translation: अनुच्छेद\n",
            "\n",
            "==================================================\n",
            "\\English sentence: a ppend to file…\n",
            "Actual Translation: फाइल में जोड़ें\n",
            "Predicted Translation: फाइल में जोड़ें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: libraries\n",
            "Actual Translation: लाइब्रेरीज़ः\n",
            "Predicted Translation: लाइब्रेरीज़ः\n",
            "\n",
            "==================================================\n",
            "\\English sentence: project doesn t allow to set properties\n",
            "Actual Translation: परियोजना को सेट\n",
            "Predicted Translation: परियोजना को सेट\n",
            "\n",
            "==================================================\n",
            "\\English sentence: burning flags to be used\n",
            "Actual Translation: बर्निंग फ्लैग्स जिसे प्रयोग करना है\n",
            "Predicted Translation: बर्निंग फ्लैग्स जिसे प्रयोग करना है\n",
            "\n",
            "==================================================\n",
            "\\English sentence: bookmark selected accessible\n",
            "Actual Translation: चुने गए एक्सेसेबलों को पुस्तकचिह्नित करें\n",
            "Predicted Translation: चुने गए एक्सेसेबलों को पुस्तकचिह्नित करें\n",
            "\n",
            "==================================================\n",
            "Mean Bleu Score = 0.29828954347507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concat model"
      ],
      "metadata": {
        "id": "zH0d1zmyEacz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "tf.keras.backend.clear_session()\n",
        "concat_model = encoder_decoder(inp_vocab_size = eng_vocab_size, out_vocab_size = hi_vocab_size,\n",
        "                            embedding_size = 128, enc_lstm_units = 128, dec_lstm_units = 128,\n",
        "                            enc_input_length = enc_input_length, dec_input_length = dec_input_length,\n",
        "                            score_fun = 'concat', att_units = 128)\n",
        "#compiling the model\n",
        "concat_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = loss_function)\n",
        "#defining the callbacks\n",
        "logdir = '/content/log/concat_model/'\n",
        "# call back of tensorboard\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir,histogram_freq=1, write_graph=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "callback = [tensorboard_callback, early_stop]"
      ],
      "metadata": {
        "id": "4yifJppiEXi3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "concat_model.fit(train_data_generator, validation_data = val_data_generator, \\\n",
        "              steps_per_epoch = train_eng_inp_seq.shape[0] // batch_size, \\\n",
        "              validation_steps = train_eng_inp_seq.shape[0] // batch_size,epochs = 20, callbacks = callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml98H7rIEefp",
        "outputId": "f269f591-3182-475e-cda3-95f16bea6a45"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "164/164 [==============================] - 29s 144ms/step - loss: 2.2389 - val_loss: 2.0501\n",
            "Epoch 2/20\n",
            "164/164 [==============================] - 16s 98ms/step - loss: 2.0150 - val_loss: 1.8894\n",
            "Epoch 3/20\n",
            "164/164 [==============================] - 19s 115ms/step - loss: 1.8453 - val_loss: 1.7232\n",
            "Epoch 4/20\n",
            "164/164 [==============================] - 19s 116ms/step - loss: 1.6668 - val_loss: 1.5452\n",
            "Epoch 5/20\n",
            "164/164 [==============================] - 19s 118ms/step - loss: 1.4725 - val_loss: 1.3639\n",
            "Epoch 6/20\n",
            "164/164 [==============================] - 17s 103ms/step - loss: 1.2768 - val_loss: 1.1849\n",
            "Epoch 7/20\n",
            "164/164 [==============================] - 20s 120ms/step - loss: 1.0878 - val_loss: 1.0187\n",
            "Epoch 8/20\n",
            "164/164 [==============================] - 16s 100ms/step - loss: 0.9095 - val_loss: 0.8647\n",
            "Epoch 9/20\n",
            "164/164 [==============================] - 19s 117ms/step - loss: 0.7489 - val_loss: 0.7297\n",
            "Epoch 10/20\n",
            "164/164 [==============================] - 19s 117ms/step - loss: 0.6098 - val_loss: 0.6185\n",
            "Epoch 11/20\n",
            "164/164 [==============================] - 19s 115ms/step - loss: 0.4953 - val_loss: 0.5233\n",
            "Epoch 12/20\n",
            "164/164 [==============================] - 21s 128ms/step - loss: 0.4030 - val_loss: 0.4423\n",
            "Epoch 13/20\n",
            "164/164 [==============================] - 19s 116ms/step - loss: 0.3293 - val_loss: 0.3845\n",
            "Epoch 14/20\n",
            "164/164 [==============================] - 16s 101ms/step - loss: 0.2736 - val_loss: 0.3379\n",
            "Epoch 15/20\n",
            "164/164 [==============================] - 19s 116ms/step - loss: 0.2273 - val_loss: 0.2982\n",
            "Epoch 16/20\n",
            "164/164 [==============================] - 17s 107ms/step - loss: 0.1920 - val_loss: 0.2695\n",
            "Epoch 17/20\n",
            "164/164 [==============================] - 17s 105ms/step - loss: 0.1646 - val_loss: 0.2461\n",
            "Epoch 18/20\n",
            "164/164 [==============================] - 16s 101ms/step - loss: 0.1432 - val_loss: 0.2293\n",
            "Epoch 19/20\n",
            "164/164 [==============================] - 21s 129ms/step - loss: 0.1261 - val_loss: 0.2159\n",
            "Epoch 20/20\n",
            "164/164 [==============================] - 19s 117ms/step - loss: 0.1121 - val_loss: 0.2066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f86ddabaa70>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_score = []\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# sampling 1000 datapoints randomly from test set\n",
        "for index, (_, row) in enumerate(train.sample(1000).iterrows()):\n",
        "    input_sent = row.english\n",
        "    predicted_eng = predict_attention(input_sent, concat_model, plot_attention_weights = False)\n",
        "    actual_eng = row.hi_out.replace('<end>','').strip()\n",
        "    predicted_eng = predicted_eng.replace('<end>','').strip()\n",
        "\n",
        "    # printing Translation Pairs\n",
        "    if (index + 1)%100 == 0:\n",
        "        print(f\"\\English sentence: {input_sent}\")\n",
        "        print(f\"Actual Translation: {actual_eng}\")\n",
        "        print(f\"Predicted Translation: {predicted_eng}\\n\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    bleu_score.append(sentence_bleu([actual_eng.split(),], predicted_eng.split()))\n",
        "\n",
        "print(f\"Mean Bleu Score = {np.mean(bleu_score)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnAVGiZvEmAk",
        "outputId": "9f142daf-4c45-45e8-d0d6-91c9908b6502"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\\English sentence: branches\n",
            "Actual Translation: निगरानी\n",
            "Predicted Translation: निगरानी\n",
            "\n",
            "==================================================\n",
            "\\English sentence: selected accessible\n",
            "Actual Translation: चुने गए एक्सेसेबेल\n",
            "Predicted Translation: चुने गए एक्सेसेबेल\n",
            "\n",
            "==================================================\n",
            "\\English sentence: save the current file with a different name\n",
            "Actual Translation: वर्तमान फ़ाइल एक भिन्न नाम से सहेजें\n",
            "Predicted Translation: वर्तमान फ़ाइल एक भिन्न नाम से सहेजें\n",
            "\n",
            "==================================================\n",
            "\\English sentence: instant value\n",
            "Actual Translation: तुरंत मान\n",
            "Predicted Translation: तुरंत मान\n",
            "\n",
            "==================================================\n",
            "\\English sentence: shortcuts\n",
            "Actual Translation: शॉर्टकट्स\n",
            "Predicted Translation: शॉर्टकट्स\n",
            "\n",
            "==================================================\n",
            "\\English sentence: use tabs for indentation\n",
            "Actual Translation: उपयोग के लिए\n",
            "Predicted Translation: उपयोग के लिए\n",
            "\n",
            "==================================================\n",
            "\\English sentence: bad argument\n",
            "Actual Translation: बुरा तर्क\n",
            "Predicted Translation: बुरा तर्क\n",
            "\n",
            "==================================================\n",
            "\\English sentence: chinese traditional\n",
            "Actual Translation: चीनी पारम्परिक\n",
            "Predicted Translation: चीनी पारम्परिक\n",
            "\n",
            "==================================================\n",
            "\\English sentence: pid\n",
            "Actual Translation: \n",
            "Predicted Translation: \n",
            "\n",
            "==================================================\n",
            "\\English sentence: name x y\n",
            "Actual Translation: नाम\n",
            "Predicted Translation: नाम\n",
            "\n",
            "==================================================\n",
            "Mean Bleu Score = 0.2409878945641063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "concat_model.save_weights('/content/model_save',save_format='tf')\n",
        "\n",
        "# # Recreate the exact same model purely from the file\n",
        "# new_model = keras.models.load_model('path_to_my_model')\n"
      ],
      "metadata": {
        "id": "llCD8brFExdq"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('concat_model', 'zip', '/content/model_save')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cw5OUUVgLo6D",
        "outputId": "006a952c-1841-4ca1-8fa6-84e206cfe628"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/concat_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpJRqQtfMWMK"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}